{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#coppafisher","title":"Coppafisher","text":"<p>Coppafisher is an open source data analysis Python package for COmbinatorial Padlock-Probe-Amplified Fluorescence In Situ Hybridization (coppafish) datasets. A series of 3D microscope images are arranged into tiles, rounds and channels. For each sequencing round, every wanted gene spot is fluoresced by a dye. By the end of all rounds, each gene has a unique, barcode-like sequence of dyes called the gene code. Coppafisher is a data analysis pipeline to assign genes to spots by their gene codes in 3D.</p> <ul> <li> Zarr for image compression</li> <li> PyTorch for GPU/CPU acceleration</li> <li> Napari for 3D visualisation</li> <li> Dash for web interaction</li> </ul> <p>See installation on how to install our software, and usage to run coppafisher on your dataset. For details about coppafisher's methodology, see the method. Some vocabulary might be unfamiliar, please see the glossary for reference.</p> Gene calling on a tile."},{"location":"#installation","title":"Installation","text":""},{"location":"#prerequisites","title":"Prerequisites","text":"<ul> <li>Windows or Linux. MacOS is not tested.</li> <li>Python 3.11 or 3.12.</li> <li>Git.</li> <li>64GB of memory for tile sizes ~<code>64x2048x2048</code> pixels (recommended).</li> <li>Nvidia GPU with Cuda 12.4 support (optional).</li> </ul>"},{"location":"#environment","title":"Environment","text":"<p>Install coppafisher software from within an environment. We will use a conda environment, so miniconda or anaconda is required.</p> <p>First, build an environment and update pip (recommended)</p> <pre><code>conda create -n coppa python=3.12\nconda activate coppa\npython -m pip install --upgrade pip\n</code></pre> <p>coppa can be changed to any name.</p> Environment naming <p>Avoid putting the word <code>coppafisher</code> into the environment name because this is the same name as the Python package, which could cause bugs.</p>"},{"location":"#install","title":"Install","text":"<p>Clone the latest coppafisher version locally</p> <pre><code>git clone --depth 1 https://github.com/paulshuker/coppafisher.git\n</code></pre> Install a specific version <p>You can instead install specific coppafisher versions, like version 1.0.0</p> <pre><code>git clone --depth 1 --branch 1.0.0 https://github.com/paulshuker/coppafisher.git\n</code></pre> <p>Check the tags for version options.</p> <p>install package dependencies</p> <pre><code>cd coppafisher\npython -m pip install -r requirements.txt\n</code></pre> <p>install PyTorch with both CPU and Cuda 12.4 support by</p> <pre><code>python -m pip install -r requirements-torch.txt\n</code></pre> Check the GPU is detected <p>If you have an Nvidia GPU with working drivers, you can check that it is detected in the python terminal</p> <pre><code>import torch\ntorch.cuda.is_available()\n</code></pre> <p>which should show true.</p> <p>Finally, install coppafisher by</p> <pre><code>python -m pip install .\n</code></pre> <p>You can now safely delete the locally cloned coppafisher repository</p> <pre><code>cd ..\nrm -rf coppafisher\n</code></pre>"},{"location":"#updating","title":"Updating","text":"<p>Coppafisher will not automatically install updates. But, you will see a warning at the start of a pipeline if a new online version is available.</p> <p>To update version, delete the old conda environment by</p> <pre><code>conda env remove -yn coppa\n</code></pre> <p>Now follow all installation instructions again.</p> <p>Keep all output data (including the notebook) when updating coppafisher versions. If data saved to disk is now deprecated, coppafisher will automatically suggest a course of action when it is run again.</p>"},{"location":"advanced_usage/","title":"Advanced Usage","text":""},{"location":"advanced_usage/#change-configuration","title":"Change configuration","text":"<p>Each coppafisher section is saved as separate notebook page(s). To change the config variables and re-run the coppafisher pipeline, you can delete the notebook and all output directory files and re-run again. But, if you only wished to re-run starting from an intermediate stage, you can delete all subsequent stages and output files. To see what valid stages of coppafisher you can re-run starting from, in chronological order, in the python terminal</p> <pre><code>from coppafisher.compatibility import CompatibilityTracker\n\ntracker = CompatibilityTracker()\ntracker.print_stage_names()\n</code></pre> <p>As an example, if you wished to know how to start from the stage \"find_spots\" again</p> <pre><code>from coppafisher.compatibility import CompatibilityTracker\n\ntracker = CompatibilityTracker()\nprint(\"\\n\".join(tracker.get_start_from(\"find_spots\")))\n</code></pre> <p>and follow the instructions given. Then, you are safe to change the configuration for all sections after find spots. If you are told to delete notebook page(s), see here.</p>"},{"location":"advanced_usage/#skipping-bad-microscope-images","title":"Skipping bad microscope images","text":"<p>You may have one or more images that are taken which are corrupted, empty, or not as bright as expected. When this happens, you can tell coppafisher to run without these images. To do this, specify each tile (<code>t</code>), round (<code>r</code>), channel (<code>c</code>) image by going to your custom config file and add the line</p> <pre><code>[basic_info]\n; Keep other options.\nbad_trc = t1, r1, c1, t2, r2, c2, ...\n</code></pre> <p>under the <code>basic_info</code> section. Each set of brackets represents one image to ignore. This allows for meaningful results to be salvaged from an incomplete tile.</p>"},{"location":"advanced_usage/#create-a-background-process","title":"Create a background process","text":"<p>Large datasets can have a long compute time (in the order of days). It is recommended to run these by setting them up as a background process. It is not recommended to run multiple large datasets at once since they will be fighting for memory, CPU, and disk I/O resources. Running in the background depends on the operating system:</p>"},{"location":"advanced_usage/#linux","title":"Linux","text":"<p>Start a background process from a terminal with the coppafisher conda environment activated</p> <pre><code>nohup python3 -m coppafisher /path/to/config.ini &amp;\n</code></pre> <p>the background process will run, even if the terminal is now closed. Follow its progress by</p> <pre><code>tail -f nohup.out\n</code></pre> <p>press Ctrl + C to stop following. The process can be killed by finding it after running a command like <code>htop</code>, highlighting it, press F9, then Enter to kill it. Press q to exit the <code>htop</code> view.</p>"},{"location":"advanced_usage/#windows","title":"Windows","text":"<p>Open command prompt or powershell, run the command</p> <pre><code>start /b python -m C:\\path\\to\\config.ini\n</code></pre> <p>Try to keep the command prompt open to watch the progress. Do not log out or shutdown the PC while the process is still running.</p>"},{"location":"advanced_usage/#delete-notebook-page","title":"Delete notebook page","text":"<p>To remove a notebook page, in the python terminal</p> <pre><code>from coppafisher import Notebook\n\nnb = Notebook(\"/path/to/notebook\")\nnb.delete_page(\"page_name\")\n</code></pre> <p>For example, to remove the stitch page</p> <pre><code>from coppafisher import Notebook\n\nnb = Notebook(\"/path/to/notebook\")\nnb.delete_page(\"stitch\")\n</code></pre> <p>Any page's added after stitch are warned about. It is recommended to delete these pages as well by typing <code>y</code> then pressing enter.</p>"},{"location":"advanced_usage/#email-notification","title":"Email notification","text":"<p>To be emailed when the pipeline crashes or finishes, under section <code>[notifications]</code> in the config, add the variable <code>email_me</code> with your email address. You must have a sender email with SMTP support, this email's credentials must be given in <code>[notifications]</code> under the variables <code>sender_email</code> and <code>sender_email_password</code>. The email may be flagged as junk or not be sent altogether depending on the email address you are sending to. This has only been tested for an \"outlook.com\" Microsoft email.</p>"},{"location":"advanced_usage/#generate-gene-codes","title":"Generate gene codes","text":"<p>Generate gene codes automatically in the python terminal by</p> <pre><code>from coppafisher.utils import reed_solomon_codes\n\ncodes = reed_solomon_codes(n_gene_codes, n_rounds, n_channels)\n</code></pre> <p>where <code>n_gene_codes</code> is the number of gene codes desired, <code>n_rounds</code> is the number of sequencing rounds, and <code>n_channels</code> is the number of channels. An error is thrown if the number of unique gene codes desired is impossible to create. Each channel is labelled 0, 1, 2, ... and <code>codes</code> is a dictionary. Each gene code generated can be accessed. For example, to access the first gene code: <code>codes[\"gene_0\"]</code>.</p>"},{"location":"advanced_usage/#retrieve-the-notebook-config","title":"Retrieve the Notebook config","text":"<p>Every notebook page has associated config section(s) saved to disk. You can look at each notebook page's associated config section(s). For example, to see the associated config section(s) for the filter page, in the python terminal</p> <pre><code>from coppafisher import Notebook\n\nnb = Notebook(\"/path/to/notebook\")\nnb.filter.associated_configs  # Dictionary of associated config sections.\n</code></pre>"},{"location":"basic_usage/","title":"Basic Usage","text":""},{"location":"basic_usage/#input-data","title":"Input data","text":"<p>Coppafisher requires raw, <code>uint16</code> microscope images, metadata, and a configuration file. We currently only support raw data in ND2, JOBs, numpy, or tif format. If your data is not already in one of these formats, we recommend configuring your data into numpy format. The tif file format is also explained below.</p> <p>There must be an anchor round. There must be an anchor channel (this can be a sequencing channel). There must be a dapi channel in every sequencing round and the anchor round. The tiles must have at least four z planes. Use a number of z planes that is a multiple of two.</p> Tile Indexing Conventions <p>Input tiles can be indexed differently to coppafisher. You can use this diagnostic.</p>"},{"location":"basic_usage/#numpy","title":"Numpy","text":"<p>Each round is separated between directories. Label sequencing round directories <code>0</code>, <code>1</code>, etc. We recommend using dask, this is installed in your coppafisher environment by default. The code to save input data:</p> <pre><code>import os\nimport dask.array\n\nraw_path = \"/path/to/raw/data\"\ndask_chunks = (1, n_total_channels, n_y, n_x, n_z)\nfor r in range(n_seq_rounds):\n    save_path = os.path.join(raw_path, f\"{r}\")\n    image_dask = dask.array.from_array(seq_image_tiles[r], chunks=dask_chunks)\n    dask.array.to_npy_stack(save_path, image_dask)\n\n# Anchor round\nsave_path = os.path.join(raw_path, \"anchor\")\nimage_dask = dask.array.from_array(anchor_image, chunks=dask_chunks)\ndask.array.to_npy_stack(save_path, image_dask)\n</code></pre> <p>where <code>n_...</code> variables represent counts (integers), <code>seq_image_tiles</code> is a numpy array of shape <code>(n_seq_rounds, n_tiles, n_total_channels, n_y, n_x, n_z)</code>, while <code>anchor_image</code> is a numpy array of shape <code>(n_tiles, n_total_channels, n_y, n_x, n_z)</code>. Note that <code>n_y</code> must equal <code>n_x</code>.</p>"},{"location":"basic_usage/#tif","title":"Tif","text":"<p>Every round (anchor included) must be a .tif file located inside of the <code>input_dir</code>. They must have the shape <code>(n_tiles * n_total_channels * n_z, n_y, n_x)</code>. The first axis is flattened such that the first n_total_channels are tile 0 and z plane 0 on each channel, then the next n_total_channels are tile 0 and z plane 1 on each channel. Then after n_z z planes the next n_total_channels are tile 1 and z plane 0 on each channel etc...</p>"},{"location":"basic_usage/#metadata","title":"Metadata","text":"<p>The metadata file required for numpy and tif input formats. It must be saved in the same location as the raw input files. This can be done using Python:</p> <pre><code>import json\nimport os\n\n# CHANGE THESE PARAMETERS:\noutput_dir = \"/path/to/output/directory/\"\nn_tiles = 2\nn_rounds = 7\nn_total_channels = 28\nn_y = 2048\nn_z = 50\npixel_size_xy = 0.3\npixel_size_z = 0.9\ntile_origins_yx = [[1, 0], [0, 0]]\n\nif __name__ == \"__main__\":\n    metadata = {\n        \"n_tiles\": n_tiles,\n        \"n_rounds\": n_rounds,\n        \"n_channels\": n_total_channels,\n        \"tile_sz\": n_y,  # or n_x\n        \"pixel_size_xy\": pixel_size_xy,\n        \"pixel_size_z\": pixel_size_z,\n        \"tile_centre\": [n_y / 2, n_y / 2, n_z / 2],\n        \"tilepos_yx\": tile_origins_yx,\n        \"tilepos_yx_nd2\": list(reversed(tile_origins_yx)),\n        \"channel_camera\": [1] * n_total_channels,\n        \"channel_laser\": [1] * n_total_channels,\n        \"nz\": n_z,\n    }\n    file_path = os.path.join(output_dir, \"metadata.json\")\n    with open(file_path, \"w\") as f:\n        json.dump(metadata, f, indent=4)\n</code></pre> <p><code>n_tiles</code> must be the total number of tiles inside of the raw inputted files (even if you only plan on selecting a subset of them). Similarly, <code>n_total_channels</code> must be the total number of channels in the inputted raw files.</p> <p><code>pixel_size_xy</code> is the size of a pixel along the y/x axes in microns. <code>pixel_size_z</code> is the size of a pixel along the z axis in microns. <code>n_y</code> is the number of pixels along y/x for a single tile. <code>n_z</code> is the number of pixels along z for a single tile. <code>tile_origins_yx</code> is a list of lists which tells coppafisher where each tile is relative to one another. For example, a 2x2 of tiles going around clockwise starting from the top-left would be <code>tile_origins_yx = [[0, 0], [0, 1], [1, 1], [1, 0]]</code>.</p>"},{"location":"basic_usage/#code-book","title":"Code book","text":"<p>A code book is a <code>.txt</code> file that tells coppafisher the gene codes for each gene. Each digit is the dye index for each sequencing round. An example of a four gene code book is</p> <pre><code>gene_0 0123012\ngene_1 1230123\ngene_2 2301230\ngene_3 3012301\n</code></pre> <p>the names (<code>gene_0</code>, <code>gene_1</code>, ...) can be changed. Do not assign any genes a constant gene code like <code>0000000</code>. To learn how the codes can be generated, see advanced usage. For details on how the codes are best generated, see <code>reed_solomon_codes</code> in the source code. See Wikipedia for algorithmic details on how gene codes are best selected.</p>"},{"location":"basic_usage/#configuration","title":"Configuration","text":"<p>There are configuration variables used throughout the coppafisher pipeline. Most of these have reasonable default values, but some must be set by the user and you may wish to tweak other values for better performance. Save the config text file, like <code>dataset_name.ini</code>. The config file should contain, at the minimum:</p> <pre><code>[file_names]\n; MUST SPECIFY input_dir, output_dir, tile_dir, code_book.\ninput_dir =\noutput_dir =\ntile_dir =\ncode_book =\n; This can be .npy, .tif, .nd2 or jobs.\nraw_extension = .npy\n; The names of the ND2 files (excluding the file extension above).\nround = round0, round1, round2, round3, round4, round5, round6\nanchor = anchor\n; Optional, leave blank if you do not have a fluorescent bead file.\nfluorescent_bead_path =\n\n[basic_info]\n; The names of the dyes given, must match the number of dyes used in the gene codebook.\ndye_names = dye_0, dye_1, dye_2, dye_3\n; Optional, leave blank to run on all tiles.\nuse_tiles =\n; Round indices (starting from 0) located in the input files.\nuse_rounds = 0, 1, 2, 3, 4, 5, 6\n; Channel indices (starting from 0) located in the input files.\nuse_channels = 5, 9, 10, 14, 15, 18, 19, 23, 27\n; Optional, leave blank to run on all z planes.\nuse_z =\n; The index of the anchor round.\nanchor_round = 7\n; The index of the anchor channel.\nanchor_channel = 1\n; The index of the dapi channel.\ndapi_channel = 0\n\n[stitch]\n; The percentage overlap between adjacent tiles.\nexpected_overlap = 0.1\n\n[call_spots]\ntarget_values = 1, 1, 1, 1\nd_max = 0, 1, 2, 3\n</code></pre> <p><code>raw_extension</code> is <code>.npy</code> for numpy input, <code>.tif</code> for tif input, <code>.nd2</code> for nd2 input, and <code>jobs</code> for JOBs input.</p> <p><code>tile_dir</code> is the tile directory, where extract images are saved to, it should be empty before running coppafisher. <code>output_dir</code> is where the notebook and PDF diagnostics are saved, it should also be blank before running. More details about every config variable can be found at  <code>coppafisher/setup/default.ini</code> in the source code.</p> <p><code>target_values</code> and <code>d_max</code> must both have <code>n_seq_channels</code> numbers, one for each channel. See call spots for details on how to set the values. If you are unsure, set target_values to all ones and d_max to the brightest channel in each dye.</p> Unique anchor raw file indices <p>If your anchor raw file has unique channel locations compared to the sequencing raw files, set <code>raw_anchor_channel_indices</code> under the <code>file_names</code> section in the config. Go to  <code>coppafisher/setup/default.ini</code> and search for <code>raw_anchor_channel_indices</code> for a description and usage.</p>"},{"location":"basic_usage/#running","title":"Running","text":"<p>Coppafisher must be run with a configuration file. In the command line</p> <pre><code>python3 -m coppafisher /path/to/config.ini\n</code></pre> <p>Or programmatically, using a python script</p> <pre><code>from coppafisher import run_pipeline\n\nrun_pipeline(\"/path/to/config.ini\")\n</code></pre> <p>which can then be run from the command line</p> <pre><code>python3 coppafisher_script_name.py\n</code></pre>"},{"location":"basic_usage/#runtime","title":"Runtime","text":"<p>For an estimate of your pipeline runtime<sup>1</sup>, in the Python terminal:</p> <pre><code>from coppafisher.utils import estimate_runtime\n\nestimate_runtime()\n</code></pre> <p>then type in the relevant information when prompted.</p> <ol> <li> <p>All time estimations are made using an Intel i9-13900K @ 5.500GHz, NVIDIA RTX 4070Ti Super (optional), and NVMe local SSD. Raw, ND2 input files were saved on a server with read speed of ~200 MB/s.\u00a0\u21a9</p> </li> </ol>"},{"location":"call_spots/","title":"Call Spots","text":"<p>The Call Reference Spots section of the pipeline is a method of gene calling which runs quickly on a small set of spots (\\(\\approx\\) 50, 000 per tile) of the anchor image. Initially, this was our final mode of gene calling, but has since been superseded by OMP, which differs from Call Spots in that it runs on several more pixels, regardless of whether they have been detected as a spot.</p> <p>Despite this, the call spots section is still a crucial part of the pipeline as it estimates several important parameters used in the OMP section.</p> <p>Some of the most important exported parameters of this section are:</p> <ul> <li> <p>Colour Normalisation Factor \\(\\mathbf{A}\\):  \\((n_{\\text{t}} \\times n_{\\text{r}} \\times n_{\\text{c}})\\) array which multiplies the colours to minimise any systematic brightness variability between different tiles, rounds and channels and maximise spectral separation of dyes,</p> </li> <li> <p>Bleed Matrix \\(\\mathbf{B}\\): \\((n_{\\text{d}} \\times n_{\\text{c}})\\) array of the typical channel spectrum of each dye.</p> </li> <li> <p>Bled Codes \\(\\mathbf{K}\\): \\((n_{\\text{g}} \\times n_{\\text{r}} \\times n_{\\text{c}})\\) array of the expected colour spectrum for each gene.</p> </li> </ul>"},{"location":"call_spots/#algorithm-breakdown","title":"Algorithm Breakdown","text":"Algorithm Flowchart showing how all variables and steps of the pipeline are related. <p>The inputs to the algorithm are:</p> <ul> <li> <p>Raw spot colours \\(F_{src}\\) for all spots \\(s\\) (defined as local maxima of round \\(r_{\\text{anchor}}\\), channel \\(c_{\\text{anchor}}\\)) and the tile \\(t(s)\\) they belong to.</p> </li> <li> <p>A list of genes \\(g\\) and their associated dye codes \\(d(g, r)\\) for each round \\(r\\). These codes were generated by the Reed-Solomon Algorithm which should minimise the number of overlap between codes.</p> </li> <li> <p>A raw bleed matrix \\(\\mathbf{B_{\\textrm{raw}}}\\) of shape \\((n_{\\text{dyes}} \\times n_{\\text{c}})\\) obtained from images of free-floating drops of each dye.</p> </li> </ul>"},{"location":"call_spots/#0-preprocessing","title":"0: Preprocessing","text":"<p>The purpose of this step is to approximately equalise the brightness of different tiles, rounds and channels and to remove any background which is constant across rounds from each spot.</p> <p>We transform the raw spot colours \\(F_{src}\\) as follows:</p> \\[F_{src} \\mapsto \\tilde{A}_{t(s)rc}F_{src}\\] <p>In the formula above:</p> <ul> <li>The initial normalisation factor \\(\\tilde{A}_{trc}\\) is defined as</li> </ul> \\[ \\tilde{A}_{trc} = \\dfrac{1}{\\text{Percentile}_s(F_{src}, 95)} \\] <p>for all spots \\(s\\) in tile \\(t\\). This is a good estimate of the scaling factor needed to make the brightest spots in each tile, round and channel have the same intensity.</p> If <code>background_subtract</code> in the config is set to true (typically false) \\[ F_{src} \\mapsto F_{src} - \\text{Percentile}_r(F_{src}, 25) \\] <p>For 7 rounds, this is the brightness of the second dimmest round of the scaled spot colours in channel c. This is a good estimate of the constant signal in channel c across all rounds, which we want to remove.</p> <p>We define the intensity of spot \\(s\\) as</p> \\[ I(s) = \\min_r\\Big(\\max_c(|F_{src}|)\\Big) \\] <p>which will be useful later for refined spot selection by ensuring there is brightness in every sequencing round.</p>"},{"location":"call_spots/#1-initial-gene-assignment","title":"1: Initial Gene Assignment","text":"<p>The purpose of this step is to provide some preliminary gene assignments that will allow us to estimate the bleed matrix and the bled codes. We will work extensively with the bleed matrix in these calculations, but bear in mind that this is the raw bleed matrix \\(\\mathbf{B_{\\textrm{raw}}}\\).</p> <p>We'd like to define a probability that spot \\(s\\) (fluorescence \\(F_{src}\\)) comes from gene \\(g\\), and we'd like this probability to have the following properties:</p> <ol> <li> <p>The probability of round \\(r\\) being assigned to dye \\(d\\) should be invariant to changes in the overall brightness of \\(\\mathbf{F_{sr}}\\),</p> </li> <li> <p>the probabilities of each round \\(r\\) should be independent.</p> </li> </ol> Why these properties? <p>Property 1 is desirable because of the way the bridge probes work in the experiment, as shown below.</p> <p><p>  The 3 probe system. </p></p> <p>Upon every mRNA transcript of interest, several padlock-probes are attached. These stay fixed in place throughout the experiment. To illuminate each gene with the expected dye in each round, bridge probes (which are gene-specific on one arm and dye-specific on the other) are transported to all the padlock probes associated with this spot and ligated.</p> <p>The brightness of each gene in each round is proportional to the amount of bridge probes that have ligated. Unfortunately, the number of bridge probes varies wildly between genes and rounds, giving rise to systematic differences in brightness between genes and rounds.</p> <p>Normalising the brightnesses of each spot in each round is a way to get around this problem.</p> <p><p>  Spots assigned to the gene Chrm 1 had many more bridge probes in round 4 than round 3, leading to systematic brightness differences. </p></p> <p>Property 2 is only approximately true, but independence between rounds makes the formula for the probability of a spot being assigned to a gene much simpler.</p> <p>Let:</p> <ul> <li> <p>\\(\\mathbf{f} = (\\mathbf{f_1}, \\ldots, \\mathbf{f_{n_r}}) ^ T\\) be the \\((n_r \\times n_c)\\) round-normalised fluorescence matrix of the spot,</p> </li> <li> <p>\\(\\mathbf{b}_g = (\\mathbf{B_{d(g, 1)}}, \\ldots, \\mathbf{B_{d(g, n_r)}}) ^ T\\) be the \\((n_r \\times n_c)\\) round-normalised bled code for gene \\(g\\).</p> </li> </ul> <p>We define the probability of spot \\(s\\) being assigned to gene \\(g\\) as</p> \\[ \\mathbb{P}[G = g \\mid \\mathbf{F} = \\mathbf{f}] = \\frac{\\exp(\\kappa \\mathbf{b}_g \\cdot \\mathbf{f})}{\\sum_{g'} \\exp(\\kappa\\mathbf{b}_{g'} \\cdot \\mathbf{f})},\\] <p>where \\(\\kappa\\) is a concentration parameter which controls how much the probabilities are spread out among the genes.</p> How to choose \\(\\kappa\\)? <p>The parameter \\(\\kappa\\) is set by adjusting the config parameter <code>kappa</code> and has default value 2. The value of \\(\\kappa\\) controls how much the probabilities are spread out among the genes, but does not influence the gene ordering.</p> <ul> <li> <p>\\(\\kappa = 0\\) yields a uniform distribution of probabilities between all genes,</p> </li> <li> <p>\\(\\kappa \\rightarrow \\infty\\) yields a distribution that tends to 1 for the gene with the maximum dot product and 0 for all others.</p> </li> </ul> <p><p>  Effects of varying \\(\\kappa\\) on the probabilities of a single spot. </p></p> <p>When working with larger gene panels, all probabilities are spread out more naturally, so it helps to increase \\(\\kappa\\) so that probabilities have a consistent interpretation. Out current implementation sets \\(\\kappa = 2\\) if \\(n_g &lt; 200\\) and 3 otherwise.</p> Gene Probability Derivation"},{"location":"call_spots/#dye-probabilities","title":"Dye Probabilities","text":"<p>We'll model the normalised round fluorescence vectors \\(\\mathbf{F_r}\\) arising from dye \\(d\\) as being random and distributed according to a von Mises-Fisher distribution with mean \\(\\mathbf{B_d}\\) and concentration parameter \\(\\kappa\\).</p> <p>This model has probability density function</p> \\[\\mathbb{P}[\\mathbf{F_{r}} = \\mathbf{f_r} \\mid D = d] =  M_{\\kappa} \\exp(\\kappa\\mathbf{f_r} \\cdot \\mathbf{B_d}),\\] <p>where \\(\\mathbf{f_r}\\) is a unit vector and \\(M_{\\kappa}\\) is a normalization constant we don\u2019t need to worry about.</p>"},{"location":"call_spots/#gene-probabilities","title":"Gene Probabilities","text":"<p>Now let \\(\\mathbf{F} = (\\mathbf{F_1}, \\ldots, \\mathbf{F_{n_r}}) ^ T\\) be the \\((n_r \\times n_c)\\) matrix of normalised fluorescence vectors of each round \\(r\\) of a spot \\(s\\). By independence between rounds, the probability of observing the fluorescence \\(\\mathbf{f}\\) from a spot of gene \\(g\\) is just the product of the probabilities that each round \\(r\\) is assigned to dye \\(d(g, r)\\). In equations, this simplifies nicely to:</p> \\[ \\begin{aligned} \\mathbb{P}[\\mathbf{F} = \\mathbf{f} \\mid G = g] &amp;= \\prod_r \\mathbb{P}[\\mathbf{F_{r}} = \\mathbf{f_r} \\mid D = d(g, r)] \\\\ &amp;= \\prod_r M_{\\kappa} \\exp \\left( \\kappa\\mathbf{f_r} \\cdot \\mathbf{B_{d(g, r)}} \\right) \\\\ &amp;= M_{\\kappa}^{n_r} \\exp \\left( \\kappa \\sum_r \\mathbf{f_r} \\cdot \\mathbf{B_{d(g, r)}} \\right) \\\\ &amp;=  M_{\\kappa}^{n_r} \\exp(\\kappa \\mathbf{f \\cdot b_g}), \\end{aligned} \\] <p>where</p> <ul> <li> <p>\\(\\mathbf{f} = (\\mathbf{f_1}, \\ldots, \\mathbf{f_{n_r}}) ^ T\\) is the observed round-normalised \\((n_r \\times n_c)\\) fluorescence matrix of the spot,</p> </li> <li> <p>\\(\\mathbf{b_g} = (\\mathbf{B_{d(g, 1)}}, \\ldots, \\mathbf{B_{d(g, n_r)}}) ^ T\\) is the \\((n_r \\times n_c)\\) matrix of the bled code for gene \\(g\\),</p> </li> <li> <p>the dot product \\(\\mathbf{f \\cdot b_g}\\) is the Frobenius Inner Product for Matrices, ie: the sum of the elementwise product of the two matrices.</p> </li> </ul> <p>We have so far only defined the probability of \\(\\mathbf{F} = \\mathbf{f}\\) given \\(G = g\\). We can find the probability of \\(G = g\\) given \\(\\mathbf{F} = \\mathbf{f}\\) using Bayes' Rule:</p> \\[ \\mathbb{P}[G = g \\mid \\mathbf{F} = \\mathbf{f}] = \\dfrac{\\mathbb{P}[\\mathbf{F} = \\mathbf{f} \\mid G = g] \\mathbb{P}[G = g]}{ \\mathbb{P}[\\mathbf{F} = \\mathbf{f}]}. \\] <p>For the priors, we will assume that:</p> <ul> <li> <p>\\(\\mathbb{P}[G = g] = \\frac{1}{n_g}\\) (ie: all genes are equally likely),</p> </li> <li> <p>\\(\\mathbb{P}[\\mathbf{F} = \\mathbf{f}] = \\sum_g \\mathbb{P}[\\mathbf{F} = \\mathbf{f} \\mid G = g] \\mathbb{P}[G = g] = \\frac{1}{n_g} \\sum_g M_{\\kappa}^{n_r} \\exp(\\kappa \\mathbf{b}_g \\cdot \\mathbf{f})\\), (ie: \\(\\mathbf{f}\\) comes from one of the genes)</p> </li> </ul> <p>This gives us the final probability:</p> \\[ \\mathbb{P}[G = g \\mid \\mathbf{F} = \\mathbf{f}] = \\frac{\\exp(\\kappa \\mathbf{b}_g \\cdot \\mathbf{f})}{\\sum_g \\exp(\\kappa\\mathbf{b}_g \\cdot \\mathbf{f} )}\\]"},{"location":"call_spots/#2-bleed-matrix-calculation","title":"2: Bleed Matrix Calculation","text":"<p>The purpose of this step is to compute an updated estimate of the bleed matrix.</p> <p>Set some probability threshold \\(\\gamma\\) (in the config file \\(\\gamma\\) is called <code>gene_prob_thresold</code> and has default value 0.9). Set an intensity threshold \\(\\delta\\) (in the config file \\(\\delta\\) is called <code>gene_intensity_threshold</code> and has default value 0.2). We define the following sets:</p> \\[ \\mathcal{S} = \\{ s : p(s) &gt; \\gamma \\space \\cap \\space I(s) &gt; \\delta \\}, \\] \\[ G_{rd} = \\{ g : d(g,r) = d \\}, \\] \\[ J_{rd} = \\{ \\mathbf{F_{sr}} \\in \\mathbb{R}^{n_c}: s \\in \\mathcal{S}, \\ g_s \\in G_{rd} \\} \\] <p>In words, these can be described as follows:</p> <ul> <li> <p>\\(\\mathcal{S}\\) is the set of spots with \\(s\\) with high probability/intense spots,</p> </li> <li> <p>\\(G_{rd}\\) is the set of genes with dye \\(d\\) in round \\(r\\),</p> </li> <li> <p>\\(J_{rd}\\) is the set of colours of high probability/intense spots assigned to genes with dye \\(d\\) in round \\(r\\).</p> </li> </ul> <p>By taking the union of \\(J_{rd}\\) across rounds, we end up with a set of reliable colour vector estimates for dye \\(d\\):</p> \\[ \\mathcal{J}_d = \\bigcup_r J_{rd} \\] Why do we find spots like this? <p>The simpler way to find represantitive colours for each dye would be to look at the colours for all spots \\(s\\) where \\(\\mathbf{F_{sr}} \\cdot \\mathbf{B_{raw, d}}\\) is above some threshold. This would give us a set of colours which are likely to be from dye \\(d\\).</p> <p>Our method is better for two reasons:</p> <ol> <li>The raw bleed matrix \\(\\mathbf{B_{raw}}\\) is not always good estimate of the bleed matrix.</li> <li>The central dyes have very similar colour spectra, so it is difficult to classify which dye the vector comes from by looking at round \\(r\\) alone. By using information from adjacent rounds, we can more confidently ensure that the colours we are looking at are from dye \\(d\\).</li> </ol> <p>Let \\(\\mathbf{J}\\) be the \\((n_{\\text{good spots}} \\times n_c)\\) matrix form of the set \\(\\mathcal{J}_d\\). This just means each row of \\(\\mathbf{J}\\) corresponds to a good spot and each column corresponds to a channel. Compute the first singular vectors of \\(\\mathbf{J}\\), ie: the optimal unit vectors \\(\\boldsymbol{\\omega} \\in \\mathbb{R}^{n_c}\\) and \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^{n_{\\text{good spots}}}\\) such that</p> \\[ J_{s, c} \\approx \\lambda \\eta_s \\omega_c, \\] <p>for some scalar \\(\\lambda\\). We then set \\(\\mathbf{B_d} = \\boldsymbol{\\omega}\\), which is a normalised fluorescence vector for dye \\(d.\\)</p>"},{"location":"call_spots/#3-free-bled-code-estimation","title":"3: Free Bled Code Estimation","text":"<p>The purpose of this step is to estimate a representative colour, which we call a free bled code \\(E_{grc}\\) for each gene \\(g\\).</p> <p>What makes these codes free?</p> <p>\\(E_{grc}\\) is free in the sense that for each gene \\(g\\), \\(E_{grc}\\) is only determined by spots assigned to gene \\(g\\) and not by spots assigned to other genes.</p> <p>Our method of estimating the tile-independent free bled codes \\(\\mathbf{E_{g}}\\) (and similarly the tile-dependent free bled codes \\(\\mathbf{D_{g,t}}\\)) should satisfy the following properties:</p> <ul> <li> <p>If we have no spots, we should use a prior vector \\(\\mathbf{E_g} = (\\mathbf{B_{d(g, 1)}}, \\ldots, \\mathbf{B_{d(g, n_r)}}) ^ T\\),</p> </li> <li> <p>We should allow each round \\(\\mathbf{E_{gr}}\\) to scale \\(\\mathbf{B_{d(g, r)}}\\) easily,</p> </li> <li> <p>We should allow each round \\(\\mathbf{E_{gr}}\\) to change the direction of \\(\\mathbf{B_{d(g, r)}}\\) less easily, but still allow it to change.</p> </li> </ul> Why these properties? <ul> <li> <p>Property 1 is necessary because for large gene panels we often have very few reads of each gene, meaning that we have very few samples to compute \\(\\mathbf{E_g}\\) and even fewer to compute \\(\\mathbf{D_{g, t}}\\).</p> </li> <li> <p>Property 2 is necessary because, as mentioned previously, different concentrations of bridge probes lead to systematic differences in brightness between genes in different rounds. We want to allow the brightness of each gene in each round to be scaled up or down without needing very many samples to do so.</p> </li> <li> <p>Property 3 is necessary because sometimes the way that a particular dye is expressed varies from gene to gene. An example of this is when the dyes are not completely washed out between rounds, leading to a small amount of bleedthrough from the previous round.</p> </li> </ul> <p>In the example below, both CPLX2 and FOS have dye 2 in their codes (R5 and R4 respectively), but due to incomplete washout of dye 0 in R3 of CPLX2 these genes have very different codes for dye 2.</p> CPLX2FOS <p><p>  Bleedthrough into R5, Dye 2. </p></p> <p><p>  No bleedthrough into R6, D2. </p></p> <p>The following mean satisfies all the properties mentioned above. Given \\(n\\) round fluorescence vectors \\(\\mathbf{f_1}, \\ldots, \\mathbf{f_n}\\) and a prior unit vector \\(\\mathbf{b}\\), all in \\(\\mathbb{R}^{n_c}\\), we define the parallel bayes mean of these as</p> \\[ \\mathbf{\\bar{F}}_{\\alpha\\beta}(\\mathbf{b}) = \\dfrac{\\alpha^2}{n + \\alpha^2} \\mathbf{b} + \\dfrac{1}{n + \\alpha^2} \\bigg( \\sum_i \\mathbf{f_i \\cdot b} \\bigg) \\mathbf{b} + \\dfrac{1}{n+\\beta^2} \\sum_i \\bigg( \\mathbf{f_i} - (\\mathbf{f_i} \\cdot \\mathbf{b})\\mathbf{b} \\bigg). \\] <p>The values \\(\\alpha^2\\) and \\(\\beta^2\\) are in the config file as <code>concentration_parameter_parallel</code> (default value 10) and <code>concentration_parameter_perpendicular</code> (default value 50) respectively.</p> How to choose and interpret \\(\\alpha\\) and \\(\\beta\\)? <p>The formula for \\(\\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{b})\\) is quite complcated, but it is actually quite easy to interpret once we understand what it is doing for different values of \\(\\alpha\\) and \\(\\beta\\).</p> <ul> <li> <p>If \\(\\alpha = \\beta = 0\\), this is just the average. ie: \\(\\mathbf{\\bar{F}}_{0,0}(\\mathbf{b}) = \\frac{1}{n} \\sum_i \\mathbf{f_i}\\),</p> </li> <li> <p>if \\(\\alpha = \\beta = m\\), for some positive integer \\(m\\), this is the average of \\(\\mathbf{f_1}, \\ldots, \\mathbf{f_n}\\) and \\(m\\) copies of \\(\\mathbf{b}\\), ie: $\\(\\mathbf{\\bar{F}}_{m,m}(\\mathbf{b}) = \\frac{1}{n + m} \\sum_i \\mathbf{f_i} + \\frac{m}{n + m} \\mathbf{b}\\).</p> </li> <li> <p>From the previous point, we see that if \\(\\alpha = \\beta = \\infty\\), this is just the prior vector \\(\\mathbf{b}\\), ie: \\(\\mathbf{\\bar{F}}_{\\infty, \\infty}(\\mathbf{b}) = \\mathbf{b}\\).</p> </li> <li> <p>The component of \\(\\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{b})\\) parallel to \\(\\mathbf{b}\\) has magnitude \\(\\frac{\\alpha^2 + \\sum_i \\mathbf{f_i} \\cdot \\mathbf{b}}{n + \\alpha^2}\\), which means that:</p> <ul> <li> <p>If \\(n &lt;&lt; \\alpha^2\\) this magnitude is approximately 1, so this component is approximately \\(\\mathbf{b}\\),</p> </li> <li> <p>If \\(n &gt;&gt; \\alpha^2\\) this magnitude is approximately \\(\\frac{1}{n} \\sum_i (\\mathbf{f_i} \\cdot \\mathbf{b} ) \\mathbf{b}\\), which is the magnitude of the sample mean \\(\\mathbf{\\bar{f}}\\) in the direction \\(\\mathbf{b}\\).</p> </li> </ul> </li> <li> <p>The component of \\(\\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{b})\\) perpendicular to \\(\\mathbf{b}\\) has magnitude \\(\\frac{1}{n + \\beta^2} \\sum_i ( \\mathbf{f_i} - (\\mathbf{f_i} \\cdot \\mathbf{b})\\mathbf{b} )\\) which means that:</p> <ul> <li> <p>If \\(n &lt;&lt; \\beta^2\\) this magnitude is approximately 0, so this component is approximately \\(\\mathbf{0}\\),</p> </li> <li> <p>If \\(n &gt;&gt; \\beta^2\\) this magnitude is approximately \\(\\frac{1}{n} \\sum_i \\mathbf{f_i} - (\\mathbf{f_i} \\cdot \\mathbf{b})\\mathbf{b}\\), which is the sample mean \\(\\mathbf{\\bar{f}}\\) perpendicular to \\(\\mathbf{b}\\).</p> </li> </ul> </li> </ul> <p>From this analysis, we see that \\(\\alpha^2\\) is roughly the number of spots needed to scale \\(\\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{b})\\) in the direction of \\(\\mathbf{b}\\), and \\(\\beta^2\\) is roughly the number of spots needed to scale \\(\\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{b})\\) perpendicular to \\(\\mathbf{b}\\).</p> <p>This is why we to set \\(\\alpha^2 &lt;&lt; \\beta^2\\). We want to easily scale the average in the direction of the prior vector, but not easily change its direction.</p> <p>We use these to estimate the free bled codes \\(\\mathbf{E_{gr}}\\) for each gene \\(g\\) and round \\(r\\) as follows:</p> <p>Let \\(\\mathbf{f_1}, \\ldots, \\mathbf{f_n} \\in \\mathbb{R}^{n_c}\\) be the round \\(r\\) fluorescence vectors of spots assigned to gene \\(g\\) with probability greater than \\(\\gamma\\) and let \\(\\mathbf{B_{d(g, r)}}\\) be the prior unit vector. We then set each round \\(r\\) to have free bled codes \\(\\mathbf{E_{gr}}\\) given by</p> \\[ \\mathbf{E_{gr}} = \\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{B_{d(g, r)}}). \\] <p>The case for \\(\\mathbf{D_{g, t}}\\) is exactly analogous, except we use the fluorescence vectors of spots assigned to gene \\(g\\) in tile \\(t\\) with probability greater than \\(\\gamma\\).</p> Derivation of the Parallel Bayes Mean <p>The formula for the parallel bayes mean is a maximum a posteriori estimate. This means that we view the data as coming from a particular distribution with some unkown mean \\(\\boldsymbol{\\mu}\\), which we want to estimate. We have some prior beliefs about what \\(\\boldsymbol{\\mu}\\) should be and how this should vary, which we encode in a prior distribution of potential values for \\(\\boldsymbol{\\mu}\\). The observed data has a certain probability given \\(\\boldsymbol{\\mu}\\), and by Bayes rule each \\(\\boldsymbol{\\mu}\\) has a probability given the data. The maximum a posteriori estimate \\(\\boldsymbol{\\hat{\\mu}}\\) is the value of \\(\\boldsymbol{\\mu}\\) which maximises this conditional probability distribution.</p> <p>Let \\(\\mathbf{F_1}, \\ldots, \\mathbf{F_n}\\)  be the round \\(r\\) fluorescence vectors of spots assigned to gene \\(g\\) with high probability and let \\(\\mathbf{B}_{d(g,r)}\\) be the prior unit vector.</p> <p>To begin, assume the vectors \\(\\mathbf{F_1}, \\ldots, \\mathbf{F_n}\\) are i.i.d normal random variables with mean \\(\\boldsymbol{\\mu}\\) and covariance \\(I_{n_c}\\), wihch means the sample mean is also normal with mean \\(\\boldsymbol{\\mu}\\) and covariance \\(\\frac{I_{n_c}}{n}\\). Impose a normal prior on the space of possible means:</p> \\[ \\overline{\\mathbf{F}} \\sim \\mathcal{N} \\bigg( \\boldsymbol{\\mu}, \\frac{\\boldsymbol{I_{n_c}}}{n} \\bigg) \\] \\[ \\boldsymbol{\\mu} \\sim \\mathcal{N}(\\mathbf{B}_{d(g,r)}, \\Sigma) \\] <p>where</p> \\[ \\Sigma = \\text{Diag}\\left(\\frac{1}{\\alpha^2}, \\frac{1}{\\beta^2}, \\ldots, \\frac{1}{\\beta^2}\\right), \\] <p>in the orthonormal basis \\(\\mathbf{v}_1 = \\mathbf{B}_{d(g,r)}\\), and everything else orthogonal to this.</p> <p>Set \\(\\boldsymbol{\\Lambda} =\\boldsymbol{\\Sigma}^{-1}\\), \\(\\mathbf{b} = \\mathbf{B_{d(g,r)}}\\), and recall that the normal is a conjugate prior, meaning the posterior \\(\\boldsymbol{\\mu} \\mid \\mathbf{\\overline{F}}\\) is also normal.</p> <p>To find its mode we'll solve for the zeros of the derivative of its log-density. The log-density of \\(\\boldsymbol{\\mu} \\mid \\mathbf{\\overline{F}}\\) is given by</p> \\[ \\begin{aligned} l(\\boldsymbol{\\mu}) &amp;= \\log P(\\boldsymbol{\\mu}| \\overline{\\mathbf{F}} = \\mathbf{f}) \\\\ \\\\        &amp;= \\log P(\\boldsymbol{\\mu}) + \\log P(\\overline{\\mathbf{F}} = \\mathbf{f} | \\boldsymbol{\\mu}) + C \\\\ \\\\        &amp;= -\\frac{1}{2} (\\boldsymbol{\\mu} - \\mathbf{b})^T \\boldsymbol{\\Lambda} (\\boldsymbol{\\mu} - \\mathbf{b}) - \\frac{n}{2} (\\boldsymbol{\\mu} - \\mathbf{f})^T (\\boldsymbol{\\mu} - \\mathbf{f}) + C \\end{aligned} \\] <p>This has derivative</p> \\[ \\frac{\\partial l}{\\partial \\boldsymbol{\\mu}} = - \\boldsymbol{\\Lambda} (\\boldsymbol{\\mu} - \\boldsymbol{b}) - n(\\boldsymbol{\\mu} - \\mathbf{f}) \\] <p>Setting this to \\(\\mathbf{0}\\), rearranging for \\(\\boldsymbol{\\mu}\\) and using the fact that</p> \\[ \\boldsymbol{\\Lambda} \\mathbf{v} = \\begin{cases} \\alpha^2 \\mathbf{v} &amp; \\text{if } \\mathbf{v} = \\lambda\\mathbf{b} \\\\ \\\\ \\beta^2 \\mathbf{v} &amp; \\text{otherwise} \\end{cases} \\] <p>we get</p> \\[ \\begin{aligned} \\boldsymbol{\\hat{\\mu}} &amp;= (\\Lambda + nI)^{-1}(\\Lambda \\mathbf{b} + n\\mathbf{f}) \\\\ \\\\     &amp;= (\\Lambda + nI)^{-1}(\\alpha^2 \\mathbf{b} + n\\mathbf{f}) \\\\ \\\\     &amp;= (\\Lambda + nI)^{-1}(\\alpha^2 \\mathbf{b} + n(\\mathbf{f} \\cdot \\mathbf{b})\\mathbf{b} + n(\\mathbf{f} - (\\mathbf{f} \\cdot \\mathbf{b})\\mathbf{b})) \\\\ \\\\     &amp;= (\\Lambda + nI)^{-1}((\\alpha^2 + n \\mathbf{f} \\cdot \\mathbf{b})\\mathbf{b} + n(\\mathbf{f} - (\\mathbf{f} \\cdot \\mathbf{b})\\mathbf{b}))\\\\ \\\\ &amp;= \\dfrac{(\\alpha^2 + n \\mathbf{f} \\cdot \\mathbf{b})}{n + \\alpha^2} \\mathbf{b} +  \\dfrac{n}{n+\\beta^2} \\bigg( \\mathbf{f} - (\\mathbf{f} \\cdot \\mathbf{b})\\mathbf{b} \\bigg) \\end{aligned} \\] <p>Plugging in the observed sample mean \\(\\mathbf{f} = \\frac{1}{n}\\sum_i \\mathbf{f_{i, r}}\\) yields our estimate \\(\\boldsymbol{\\hat{\\mu}}\\).</p>"},{"location":"call_spots/#4-round-and-channel-normalisation","title":"4: Round and Channel Normalisation","text":"<p>The purpose of this step is to find a scale factor \\(V_{rc}\\) for each round \\(r\\) and channel \\(c\\) which gets as many of our spots as close as possible to their target values. We will then multiply \\(V_{rc}\\) by the free bled codes \\(E_{grc}\\) to get the constrained bled codes \\(K_{grc}\\).</p> <p>What makes these codes constrained?</p> <p>The codes \\(K_{grc}\\) are constrained in the sense that the value of \\(K_{grc}\\) is determined by several genes other than \\(g\\).</p> <p>These codes have nice global properties, like as many genes as possible being as close as possible to their target values, but will not be representative of the spots assigned to gene \\(g\\). This is addressed in section 5, where we will be to find a scale to get the spots as close as possible to these new constrained bled codes.</p> <p>The target values work as follows:</p> <ul> <li> <p>\\(T\\) is defined as <code>target_values</code> in the config file as a list of length \\(n_c\\).</p> </li> <li> <p>\\(T_c\\) is the target value for channel \\(c\\) in its representative dye \\(d_{\\textrm{max}}(c)\\),</p> </li> <li> <p>\\(d_{\\textrm{max}}\\) is defined as <code>d_max</code> in the config file as a list of length \\(n_c\\).</p> </li> <li> <p>\\(d_{\\textrm{max}}(c)\\) is the dye we use to represent channel \\(c\\), and we want to get its brightness in channel \\(c\\), \\(B_{d_{\\textrm{max}}(c), c}\\) as close as possible to \\(T_c\\).</p> </li> </ul> <p>Any gene that has dye \\(d_{\\textrm{max}}(c)\\) in round \\(r\\) will have its free bled code \\(E_{grc}\\) scaled by \\(V_{rc}\\) to get as close as possible to \\(T_c\\). Since \\(E_{grc}\\) is a representative colour for all spots assigned to gene \\(g\\), this will also get the spots as close as possible to their target values.</p> <p>As in section 2 above, let \\(G_{rd}\\) be the set of genes with dye \\(d\\) in round \\(r\\) and define the loss function</p> \\[ L(V_{rc}) = \\sum_{g \\in G_{r, \\ d_{max}(c)}} \\sqrt{N_{g}} \\  \\bigg( V_{rc} \\ E_{grc} - T_{c} \\bigg)^2, \\] <p>where \\(N_g\\) is the number of high probability spots assigned to gene \\(g\\). There is no reason this has to be a square root, though if it is not, too much influence is given to the most frequent genes. We minimise this loss to obtain the optimal value</p> \\[ V_{rc} = \\dfrac{ \\sum_{g \\in G_{r, \\ d_{max}(c) }} \\sqrt{N_g} E_{grc} T_{c} } { \\sum_{g \\in G_{r, \\ d_{max}(c) }} \\sqrt{N_g} E_{grc}^2 }, \\] <p>Now define the constrained bled codes, which we will just call bled codes</p> \\[ K_{grc} = E_{grc}V_{rc}. \\]"},{"location":"call_spots/#5-tile-normalisation","title":"5: Tile Normalisation","text":"<p>The purpose of this step is to remove brightness differences between images from different tiles in the same round and channel. We do this by finding a scale factor \\(Q_{trc}\\) for each tile \\(t\\), round \\(r\\) and channel \\(c\\) which gets as many of our spots on tile \\(t\\) as close as possible to \\(K_{grc}\\).</p> <p>Our method works almost identically to step 4. Let \\(G_{rd}\\) be the genes with dye \\(d\\) in round \\(r\\). Define the loss</p> \\[ L(Q_{trc}) = \\sum_{g \\in G_{r, \\ d_{max}(c)}} \\sqrt{N_{g,t}} \\  \\bigg( Q_{trc} \\ D_{gtrc} - K_{grc} \\bigg)^2, \\] <p>where \\(N_{g, t}\\) is the number of high probability spots of gene \\(g\\) in tile \\(t\\).</p> If Q is correcting for tile differences, why does it have indices for \\(r\\) and \\(c\\)? <p>The scale factor \\(Q_{trc}\\) is defined to correct for differences in brightness between tiles, but the way that the brightness varies between tiles is completely independent for different round-channel pairs.</p> <p>This is because the cause of brightness differences between tiles is largely random from image to image, as can be observed by looking at spots in the overlapping regions of adjacent tiles in the same round and channel.</p> <p>We minimise this loss to obtain the optimal value</p> \\[ Q_{trc} = \\dfrac{ \\sum_{g \\in G_{r, \\ d_{max}(c) }} \\sqrt{N_{gt}} \\ K_{grc}  D_{gtrc}} { \\sum_{g \\in G_{r,\\ d_{max}(c) }} \\sqrt{N_{gt}}  D_{gtrc}^2 }. \\]"},{"location":"call_spots/#6-and-7-application-of-scales-computation-of-final-scores-and-bleed-matrix","title":"6 and 7: Application of Scales, Computation of Final Scores and Bleed Matrix","text":"<p>All that is left to do is multiply the spot colours \\(F_{src}\\) by the updated normalisation factor \\(Q_{trc}\\) to get the final spot colours: \\(F_{src} \\mapsto Q_{trc} F_{src}\\).</p> <p>We then compute a score between each spot colour \\(\\mathbf{F_s}\\) and each gene bled code \\(K_{grc}\\):</p> \\[ \\text{scores}(g) = \\frac{1}{N_r}\\Bigg|\\sum_{rc}(\\hat{F}_{src}\\hat{K}_{grc})\\Bigg| \\] <p>where</p> \\[ \\hat{F}_{src} = \\frac{F_{src}}{\\sqrt{\\sum_c|F_{src}|^2}}\\text{,}\\space\\space\\space \\hat{K}_{grc} = \\frac{K_{grc}}{\\sqrt{\\sum_c|K_{grc}|^2}}\\text{,}\\space\\space\\space N_r=\\sum_r1 \\] <p>The score rewards spots matching to the bled code in multiple rounds.</p> <p>An intensity for each spot is saved to the notebook and used in the Viewer. It is computed from the final, scaled colours.</p> \\[ \\text{intensity}_s = \\min_r(\\max_c(|\\mathbf{F}_{src}|)) \\] <p>This intensity should have a threshold when looking at gene results as it removes poor gene reads caused by colour that is bright in only some of the rounds. From data, a value of 0.15 is reasonable. This is the default threshold for the Viewer.</p> What could cause brightness in some rounds but not others? <p>There are many possible explanations: 1) A registration mistake has caused a misalignment in some pixels. 2) An experiment error has failed to light up a gene in a specific round. 3) An experiment error has caused bright artifacts to appear in specific rounds and not others. So we must be robust against missing round brightness. This is especially true for OMP as this runs on every image pixel, which will include background noise.</p> <p>Then use the best gene score for each spot's assigned gene:</p> <ul> <li><code>dot_product_gene_no[s]</code> = \\(\\textrm{argmax}_g (\\textrm{scores}(g))\\)</li> <li><code>dot_product_gene_score[s]</code> = \\(\\textrm{max}_g (\\textrm{scores}(g))\\)</li> </ul> <p>We also compute probabilities for each spot \\(s\\) being assigned to gene \\(g\\) as</p> <ul> <li><code>gene_prob[s, g]</code> = \\(\\dfrac{\\exp(\\kappa \\mathbf{K_{g} \\cdot F_s})}{\\sum_{g'} \\exp(\\kappa \\mathbf{K_{g'} \\cdot F_s})}\\),</li> </ul> <p>where \\(\\mathbf{F_s}\\) and \\(\\mathbf{K_{g}}\\) have both been round-normalised. Finally, with these updated gene assignments, we can compute the final bleed matrix \\(\\mathbf{B}\\) in the same way as in step 2.</p>"},{"location":"call_spots/#diagnostics","title":"Diagnostics","text":"<p>Diagnosing the quality of the gene assignments is a crucial part of the pipeline. We provide several diagnostics to help with this:</p>"},{"location":"call_spots/#view-scaling-and-bg-removal","title":"View Scaling And BG Removal","text":"<p><pre><code>from coppafisher.plot.call_spots import ViewScalingAndBGRemoval\n\nViewScalingAndBGRemoval(nb)\n</code></pre> (or simply press 'N' in the main results' viewer)</p> <p>  Viewing the background removal and scaling of a subset of isolated spots. </p> <p>This shows a subset of 10,000 isolated spots in descending order of amount of background. The images on the top row are spot colours, each flattened into a single row and demarcated into channels by the red vertical lines. The plots on the bottom row show the intensity of a bright spot in each round channel.</p> <p>This plot shows us a few things:</p> <ul> <li> <p>Certain channels have much higher background than others. The final column is a good check that the background has been removed.</p> </li> <li> <p>Different channels have different baseline brightnesses. Check that the brightnesses in the middle and final column are to your liking and similar to the target values.</p> </li> <li> <p>The final brightnesses are not all the same: this is because we imposed channel-specific target values in step 4. This is a good check that the target scaling is working as expected.</p> </li> </ul>"},{"location":"call_spots/#view-bleed-matrix","title":"View Bleed Matrix","text":"<pre><code>import matplotlib.pyplot as plt\nfrom coppafisher.plot.call_spots import ViewBleedMatrix\n\nViewBleedMatrix(nb.basic_info, nb.call_spots)\nplt.show()\n</code></pre> <p>(or simply press 'B' in the main results' viewer)</p> <p>  Viewing the bleed matrix. </p> <p>This viewer shows 3 bleed matrices, each with columns (dyes) normalised.</p> <ul> <li> <p>The first is the raw bleed matrix \\(\\mathbf{B_{raw}}\\) which is the initial estimate of the bleed matrix, used for the very first gene assignments in step 1.</p> </li> <li> <p>The second is the initial bleed matrix \\(\\tilde{\\mathbf{B}}\\) made from an SVD of high probability spots. This is scaled according to the initial scale factor \\(\\tilde{A}_{trc}\\) introduced in step 0. This is why channel 10 is so much brighter than its target value.</p> </li> <li> <p>The final bleed matrix \\(\\mathbf{B}\\) is the bleed matrix estimated from the final gene assignments, on high probability spots. This is scaled according to the final scale factor \\(A_{trc} = Q_{trc}\\tilde{A}_{trc}\\). You should be able to see the values are roughly in the same ratios as the target values.</p> </li> </ul>"},{"location":"call_spots/#view-free-and-constrained-bled-codes","title":"View Free And Constrained Bled Codes","text":"<pre><code>from coppafisher.plot.call_spots import ViewFreeAndConstrainedBledCodes\n\nViewFreeAndConstrainedBledCodes(nb)\n</code></pre> <p>This will pull up a viewer that shows you the free bled codes \\(E_{grc}\\) and the constrained bled codes \\(K_{grc}\\) from the most influential genes for a given round and channel. This is a good way to check if the target scale \\(V_{rc}\\) is working as expected.</p> <p>To view different rounds and channels, simply scroll.</p> R0C5R2C15 <p><p> <p></p> <p><p> <p></p> <p>If this works as expected, the constrained bled codes should have values close to their target values and the constrained bled codes should be more homogeneous than the free bled codes. This can be seen in the first image, where R0C5 is initially very bright, but after scaling is much closer to the brightnesses of the other rounds and channels.</p>"},{"location":"call_spots/#view-target-regression","title":"View Target Regression","text":"<pre><code>from coppafisher.plot.call_spots import ViewTargetRegression\n\nViewTargetRegression(nb)\n</code></pre> <p>This viewer is similar to the previous one in that it is showing how well the target scaling is working. It does this in a bit more detail, but is a little confusing!</p> <p>To view different rounds and channels, simply scroll.</p> R0C27R4C5 <p><p> <p></p> <p><p> <p></p> <p>In the plots above:</p> <ul> <li>Each dot is a gene, which has dyed \\(d_{\\textrm{max}}(c)\\) in round \\(r\\).</li> <li>The size of the dot is proportional to the number of spots assigned to that gene.</li> <li>The x-axis values are completely random.</li> <li>In the leftmost column, the y-axis values are the brightnesses \\(E_{grc}\\) of the genes after the initial scaling \\(\\tilde{A}_{trc}\\) but before the target scaling \\(V_{trc}\\).</li> <li>In the middle column, the y-axis values are the brightnesses \\(K_{grc}\\) of the genes after the target scaling \\(V_{trc}\\).</li> </ul> <p>It is important to check how well each round and channel is being scaled to its target value. R0C27 is pretty good, with most of the genes being pretty concentrated at the target value. R4C5 is much noisier, with many genes consistently too bright or too dim.</p>"},{"location":"call_spots/#view-tile-scale-regression","title":"View Tile Scale Regression","text":"<p><pre><code>from coppafisher.plot.call_spots import ViewTileScaleRegression\n\nViewTileScaleRegression(nb, t)\n</code></pre> This function looks at a fixed tile and then shows the regression for the tile scale factor \\(Q_{trc}\\) for each round and channel. Recall that this is the scale factor that multiplies the tile-dependent free bled codes \\(D_{gtrc}\\) to get the constrained bled codes \\(K_{grc}\\).</p> <p>As in the previous diagnostic, each spot is a gene with dye \\(d_{\\textrm{max}}(c)\\) in round \\(r\\) and the size of the dot is proportional to the number of spots assigned to that gene. Unlike the previous diagnostic, in this plot the x-values are not random, but are the brightnesses \\(D_{gtrc}\\) of the genes (averaged from spots which have been multiplied by initial scale \\(\\tilde{A}_{trc}\\)). The y-values are the brightnesses \\(K_{grc}\\).</p> <p>A couple of things to note:</p> <ul> <li> <p>Different slopes within the same column (channel) indicate that this is picking up on differences in round brightnesses for this channel on this tile.</p> </li> <li> <p>If these regressions have a low \\(R^2\\) value, the tile scaling is not working well. This may be a sign of a blank tile or poor registration.</p> </li> </ul> <p>  Viewing the background removal and scaling of a subset of isolated spots. <p>  ### View Scale Factors  <pre><code>from coppafisher.plot.call_spots import ViewScaleFactors\n\nViewScaleFactors(nb)\n</code></pre>  This simple viewer shows the target scale $V_{rc}$, the tile scale $Q_{trc}$ and the relative scale $Q_{trc}/V_{rc}$ for each round and channel.  What to expect:  - The tile scale $Q_{trc}$ should be close to $V_{rc}$ for each tile $t$. This is because $D_{gtrc}Q_{trc} \\approx K_{grc = E_{grc}V_{rc}}$. So if $E_{grc} \\approx D_{gtrc}$, then $Q_{trc} \\approx V_{rc}$.  - The relative scale measures how much we deviate from the vase where $E_{grc} = D_{gtrc}$, and should not have a huge amount of variance. In the plot above the highest value is 0.5 and the lowest is 0.35, which is a good range.  <p> <p>  ### Gene Efficiency Viewer  <pre><code>from coppafisher.plot.call_spots import ViewGeneEfficiencies\n\nViewGeneEfficiencies(nb, score_threshold=gamma, mode=gene_assignment_mode)\n</code></pre>  or press `e` in the Viewer.  <p> <p>  Each row represents a gene and each column a round. The colour of each cell is the amount of weight that gene $g$ has in round $r$. The ideal case would be homogeneous colours across the rows, indicating that each gene is equally bright in each round, but this is never the case.  Look out for:  - Genes with an abnormal amount of spots assigned to them. This is often the case for poor quality genes which look a lot like background. If this is the case, the gene probability threshod `gene_prob_thresh` in the config file should be increased.  - Genes with very high or low gene efficiencies. This should not happen if `concentration_parameter_parallel` is sufficiently high, as it typically should need at least 10 spots to scale each dye. If the gene efficiencies are incorrect, OMP will struggle to find the correct gene assignments.  ### Gene Spots Viewer <pre><code>from coppafisher.plot.call_spots import GeneSpotsViewer\n\nGeneSpotsViewer(nb, score_threshold=gamma, gene_index=g, mode=gene_assignment_mode)\n</code></pre>  (or simply click one of the genes in the gene efficiency viewer)  <p> <p>  This viewer shows the spots assigned to a particular gene above a certain threshold, under a certain gene assignment mode (either 'anchor', 'prob' or 'omp').  This is the viewer I use the most. It helps me find abnormalities that would be hard to spot otherwise, like the persistent unexpected channel 27 signal in round 0 in the images above. If a particular gene is under or over expressed, this viewer will typically tell us why. It also gives us a very nice representation of which dyes, rounds and channels are clean and which are noisy."},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#algorithm","title":"Algorithm","text":"<p>Coppafisher is built on the principle: An algorithm that performs well does not need to be changed. So, algorithms are only updated when there is evidence that it can perform better and that the current algorithm is performing worse.</p>"},{"location":"contributing/#installation","title":"Installation","text":"<p>We use a protected staging branch called <code>dev</code>, for a future release. This must be pull requested into and pass continuous integration tests. The <code>main</code> branch is pushed into from <code>dev</code> to publish a new release. <code>main</code> is always the latest stable release for users to easily install the software.</p> <p>While changing code, install coppafisher as usual but keep the downloaded local source code directory. Then install dev packages</p> Local Code Location <p>Avoid cloning coppafisher inside a subdirectory named <code>coppafisher</code> because this could cause strange errors to occur.</p> <pre><code>pip install -r requirements-dev.txt\n</code></pre> <p>Also, put coppafisher into editable mode while changing source code</p> <pre><code>pip install -e .\n</code></pre> <p>Now all local code changes immediately take affect.</p>"},{"location":"contributing/#pre-commit","title":"Pre-Commit","text":"<p>Pre-commit hooks will automatically run on every git commit. This will ensure files are consistently formatted and checked. It also runs linting rules through ruff. Use pre-commit hooks by</p> <pre><code>pre-commit install\n</code></pre> <p>You can run pre-commit checks manually as well:</p> <pre><code>pre-commit run --all-files\n</code></pre> <p>Auto-update pre-commits (recommended):</p> <pre><code>pre-commit autoupdate\n</code></pre> <p>If a commit is pushed that fails a pre-commit hook, then the GitHub integration workflow will catch it.</p>"},{"location":"contributing/#tests","title":"Tests","text":"<p>Tests are run via pytest. Scripts are unit tested by placing the test scripts inside a directory called <code>test</code> within the script's directory. All test script file names should start with <code>test_</code>. The scripts must end with their relative directory (directories) and their script file name, separated by underscores. For example, the test script for <code>coppafisher/omp/coefs.py</code> is named <code>test_omp_coefs.py</code>. Check existing tests for examples.</p>"},{"location":"contributing/#run-tests","title":"Run Tests","text":"<p>Run unit tests (~10s)</p> <pre><code>pytest\n</code></pre> <p>Run integration tests (~90s)</p> <pre><code>pytest -m integration\n</code></pre> <p>Run unit tests requiring a notebook (~20s)</p> <pre><code>pytest -m notebook\n</code></pre> <p>View code coverage by appending <code>--cov=coppafisher --cov-report term</code> to each command.</p>"},{"location":"contributing/#run-documentation-locally","title":"Run Documentation Locally","text":"<pre><code>mkdocs serve\n</code></pre> <p>Then go to http://127.0.0.1:8000/ in a modern browser.</p>"},{"location":"contributing/#code-philosophy","title":"Code Philosophy","text":"<p>We follow basic rules when coding. Anyone can code something that works, but coding it in a scaleable, maintainable way is another struggle altogether.</p> <p>Here are some specific standards to follow:</p> <ul> <li>Knowledge written down twice is bad code. Don't Repeat Yourself (DRY)!</li> <li>If a bug is found, the bug must be automatically found if it is to occur again.</li> <li>All code is black formatted.</li> <li>Every time a function is modified or created, a new unit test must be created for the function. A pre-existing unit test can be drawn from to build a new unit test, but it should be clear in your mind that you are affectively building a new function.</li> <li>Minimise <code>if</code>/<code>else</code> branching as much as possible. Exit <code>if</code>/<code>else</code> nesting as soon as possible through the use of keywords like <code>raise</code>, <code>continue</code>, <code>break</code> and <code>return</code>, whenever feasible.</li> <li>Do not over-shorten a variable or function name.</li> <li>Variables and functions are not capitalised, classes are.</li> <li>In most cases, a line of code should do only one operation.</li> <li>Every docstring for a function must be complete so a developer can re-create the function without seeing any of the existing source code.</li> <li>Each parameter in a function must have an independent, clear functionality. If two parameters are derivable from one another, you are doing something wrong. This also applies to the function's return variables.</li> <li>Minimise the number of data types a parameter can be and use common sense. For example, a parameter that can be <code>int</code> or <code>None</code> is reasonable. A parameter that can be <code>bool</code> or <code>float</code> is not reasonable.</li> <li>The documentation should update in parallel with the code. Having the documentation as part of the github repository makes this easier.</li> </ul>"},{"location":"contributing/#docstrings","title":"Docstrings","text":"<p>While not all docstrings are consistent yet, future docstrings follow the rules below:</p> <ul> <li>The code must be reproducible from the docstring alone.</li> <li>Use Google's style.</li> <li><code>`ndarray`</code> represents a numpy ndarray and <code>`zarray`</code> represents a zarr Array.</li> <li><code>`zgroup`</code> represents a zarr Group.</li> <li>Specify datatype of a <code>ndarray</code>/<code>zarray</code> when applicable. For example, to represent any floating point datatype, <code>`ndarray[float]`</code> or a uint16 by <code>`ndarray[uint16]`</code></li> <li>Specify the shape of a <code>ndarray</code>/<code>zarray</code> in brackets when applicable. For example, <code>`(n_tiles x n_rounds x n_channels_use x 3) ndarray[int32]`</code></li> <li>The use of <code>n_rounds</code> refers to the number of rounds, including the sequencing and anchor round. So, this is equal to <code>n_seq_rounds + 1</code>. We label all sequencing rounds <code>0, 1, 2, 3, ...</code> and then the anchor round is given the next unused integer. Whereas, <code>n_rounds_use</code> refers to <code>len(use_rounds)</code> which is the total number of sequencing rounds.</li> <li>Channels are slightly different because <code>use_channels</code> in the notebook can have channel indices of any positive integer value. These represent the sequencing channels. For example, <code>use_channels = 0, 5, ..., 27</code>. So, <code>n_channels</code> refers to size <code>max(use_channels) + 1</code>, i.e. the smallest shape that can be indexed by <code>use_channels</code>. Whereas, <code>n_channels_use</code> means <code>len(use_channels)</code> such that <code>0</code> represents <code>use_channels[0]</code> etc. Note that neither of these definitions includes the dapi channel/anchor channel<sup>1</sup>, which can be found at <code>nb.basic_info.dapi_channel</code> and <code>nb.basic_info.anchor_channel</code> respectively.</li> </ul> <p>Below is a docstring example that demonstrates most of the rules.</p> <pre><code>from typing import Tuple\n\nimport numpy as np\nimport torch\nimport zarr\n\n\ndef large_function(\n    arr_0: np.ndarray[np.float16],\n    arr_1: torch.Tensor,\n    arr_2: zarr.Array,\n    number: float | None = None,\n) -&gt; Tuple[zarr.Group, float, int]:\n    \"\"\"\n    An description of exactly what the function does. This docstring must contain\n    enough detail to make the exact function again, without looking at any code.\n\n    Args:\n        arr_0 (`(n_pixels x 3) ndarray[float32]`): a description of arr_0.\n        arr_1 (`(n_pixels x n_rounds x n_channels) tensor[uint32]`): a description\n            of arr_1.\n        arr_2 (`(n_pixels x n_rounds x (n_channels + 1)) zarray[uint16]`): a\n            description of arr_2.\n        number (float or none, optional): a description of number. Default: none.\n\n    Returns:\n        A tuple containing:\n            - (zgroup): zgroup_0. A zarr Group containing arrays named zarr_0,\n                zarr_1, and zarr_2.\n            - (float): variable_0. A description of variable_0.\n            - (int): variable_1. A description of variable_1.\n    \"\"\"\n    ...\n</code></pre> <ol> <li> <p>The anchor channel can be a sequencing channel, but this does not have to be the case.\u00a0\u21a9</p> </li> </ol>"},{"location":"diagnostics/","title":"Diagnostics","text":"<p>Diagnostics specific to a method are found in the method tab.</p>"},{"location":"diagnostics/#viewer","title":"Viewer","text":"<p>The Viewer is the flagship diagnostic for viewing results. It is a fast, three-dimensional view of gene reads found during call spots and OMP. The application is powered by napari.</p>"},{"location":"diagnostics/#opening","title":"Opening","text":"<p>A Viewer can be displayed once coppafisher has run through at least call spots. From the python terminal:</p> <pre><code>from coppafisher import Notebook, Viewer\n\nnb = Notebook(\"/path/to/notebook\")\nViewer(nb)\n</code></pre> <p>where a napari window will be opened.</p> <p>You can specify the colour and symbols of genes using a .csv file, then the Viewer can be opened by</p> <pre><code>from coppafisher import Notebook, Viewer\n\nnb = Notebook(\"/path/to/notebook\")\nViewer(nb, gene_marker_filepath=\"/path/to/custom/gene_marker_file.csv\")\n</code></pre> <p>see here for the default gene marker file. The gene marker file supports all napari symbols that are shown under the <code>symbol</code> parameter in their documentation.</p> <p>The default background image is a dapi image in greyscale. You can specify custom images and their colour mappings in python, e.g.</p> <pre><code>from coppafisher import Notebook, Viewer\n\nnb = Notebook(\"/path/to/notebook\")\nViewer(nb, background_images=[\"/path/to/custom/background_image.npy\", \"dapi\"], background_image_colours=[\"Reds\", \"gray\"])\n</code></pre> <p>You can specify the background_images to be <code>[\"dapi\"]</code> or <code>[\"anchor\"]</code> for 16-bit precision background images.</p> <p>The colourmaps can be any vispy or matplotlib colourmap.</p> <p>If the background image(s) are custom files, they must be of shape <code>(im_y x im_x)</code> or <code>(im_z x im_y x im_x)</code>. They can be a .npy file, a compressed .npz file with image at key <code>\"arr_0\"</code>, or a .tif file (based on the tifffile package). For further customisation, see the Viewer docstring.</p> No Background Image <p>Specify no background images by setting <code>background_images=[]</code> and <code>background_image_colours=[]</code>.</p> When Using Multiple Background Images <p>With multiple background images, you will not see a background contrast slider anymore. This is intentional. To change the settings of each background image, click on Window -&gt; Layer List and Window -&gt; Layer Controls. From these windows, you have full control over the background images by selecting one. You can change their blending modes and opacities individually.</p> Open a Subset of Tiles <p>You can open a subset of tiles from the notebook. For example, to open only tiles 0 and 1</p> <pre><code>from coppafisher import Notebook, Viewer\n\nnb = Notebook(\"/path/to/notebook\")\nViewer(nb, show_tiles=[0, 1])\n</code></pre> <p>Close the Viewer and all subplots by pressing Ctrl + C in the terminal.</p>"},{"location":"diagnostics/#description","title":"Description","text":"<p>By default, the greyscale signal in the background is the DAPI, where whiter regions indicate cells. Each gene is given a shape and colour, shown in the gene legend.</p> <p>For help with Viewer hotkeys and gene selection, press h. This includes further diagnostic subplots in the Viewer. Some require a selected spot. Select a spot by pressing 3 and clicking on a spot. Then press 4 to continue panning.</p> <p>The \"Background Contrast\" slider will affect the colour scale of the background image. \"Marker Size\" will change the size of gene spots. \"Z Thickness\" allows for multiple z planes to be displayed at once. The \"Score Thresholds\" allows the user to change the minimum and maximum spot scores to display. The \"Intensity Thresholds\" affects the minimum and maximum allowed spot intensity to display. By default, the intensity threshold is set to 0.15. The \"Method\" is the chosen method of gene calling. \"Probability\" is the Von-Mises probability method and \"Anchor\" is the anchor method (see call spots), and \"OMP\" is the Orthogonal Matching Pursuit method (see OMP).</p> Max Intensity Projection Toggle <p>It is a known issue that toggling the Max Intensity Projection off displays the wrong z plane in the Viewer since it always shows the first z plane. To fix this, just jiggle the z position using the bottom slider and it will correctly update.</p>"},{"location":"diagnostics/#registrationviewer","title":"RegistrationViewer","text":""},{"location":"diagnostics/#opening_1","title":"Opening","text":"<pre><code>from coppafisher import RegistrationViewer, Notebook\n\nnb = Notebook(\"/path/to/notebook\")\nRegistrationViewer(nb, \"/path/to/config.ini\" t=t)\n</code></pre> <p><code>t</code> is a tile index you want to view registration results for. If <code>t</code> is set to <code>None</code> (default), then the lowest tile index is displayed.</p>"},{"location":"diagnostics/#pdf-diagnostics","title":"PDF Diagnostics","text":"<p>During a pipeline run, multiple .pdf files are created for different sections. These are located in the output directory. If you want the PDFs to be created again, delete the old ones first, then run coppafisher again.</p>"},{"location":"diagnostics/#view-tile-indexing","title":"View tile indexing","text":"<p>To visualise how coppafisher has labelled your inputted tiles, use the code below</p> <pre><code>from coppafisher.plot import view_tile_indexing_grid\n\nview_tile_indexing_grid(\"/path/to/config.ini\")\n</code></pre> <p>If you use ND2 files, visualise the tile indices using</p> <pre><code>from coppafisher.plot import plot_coords_nd2_coppafish\n\nplot_coords_nd2_coppafish(\"/path/to/nd2_file.nd2\", channel=27, reverse=False)\n</code></pre> <p>where you can choose the channel index and reverse tile positions if required.</p>"},{"location":"diagnostics/#viewing-images","title":"Viewing images","text":""},{"location":"diagnostics/#extracted-images","title":"Extracted images","text":"<p>Extracted images are identical to raw images, these are viewed by</p> <pre><code>from coppafisher import Notebook, plot\n\nnb = Notebook(\"/path/to/notebook\")\nplot.view_extracted_images(nb, \"/path/to/config.ini\", tiles, rounds, channels)\n</code></pre> <p>where <code>tiles</code>, <code>rounds</code>, and <code>channels</code> are lists of integers specifying which images to view. Set these to <code>None</code> if you wish to view all of the them from the sequencing images.</p>"},{"location":"diagnostics/#filtered-images","title":"Filtered images","text":"<p>Images after the filter stage are viewed by</p> <pre><code>from coppafisher import Notebook, plot\n\nnb = Notebook(\"/path/to/notebook\")\nplot.view_filtered_images(nb, tiles, rounds, channels, apply_colour_norm_factor=False, share_contrast_limits=True)\n</code></pre> <p>where <code>tiles</code>, <code>rounds</code>, and <code>channels</code> are lists of integers specifying which images to view. Set these to <code>None</code> if you wish to view all of the them from the sequencing images. The boolean parameters can be changed if needed. You can also view the anchor round/channel. See <code>nb.basic_info.anchor_round</code> and <code>nb.basic_info.anchor_channel</code> for the indices.</p>"},{"location":"diagnostics/#intensity-images","title":"Intensity images","text":"<p>You can view the computed intensities once call spots is complete. Do this by</p> <pre><code>from coppafisher import Notebook, plot\n\nnb = Notebook(\"/path/to/notebook\")\nplot.view_intensity_images(nb, tiles, z_planes=None)\n</code></pre> <p><code>tiles</code> is a list of integers for each tile index to view. If set to <code>None</code>, the first tile is shown. When <code>z_planes</code> is <code>None</code>, the first 20 z planes are shown, you can choose to show more z planes by setting <code>z_planes</code> to any number &gt; 20. The anchor images are also displayed for reference.</p>"},{"location":"export/","title":"Export","text":""},{"location":"export/#pciseq","title":"PciSeq","text":"<p>For probabilistic cell typing with pciSeq, a DAPI background image and gene spot positions must be exported.</p>"},{"location":"export/#dapi-image-export","title":"DAPI image export","text":""},{"location":"export/#filtered-dapi","title":"Filtered DAPI","text":"<p>To export the anchor's filtered DAPI stitched image</p> <pre><code>from coppafisher import Notebook\nfrom coppafisher.results import export_pciseq_dapi_image\n\nnb = Notebook(\"/path/to/notebook\")\nexport_pciseq_dapi_image(nb)\n</code></pre> <p>The DAPI image can then be loaded into memory by</p> <pre><code>import numpy as np\n\ndapi_image = np.load(\"/path/to/dapi_image.npz\")[\"arr_0\"]\n</code></pre>"},{"location":"export/#unfiltered-dapi","title":"Unfiltered DAPI","text":"<p>To export the anchor's unfiltered DAPI stitched image</p> <pre><code>from coppafisher import Notebook\nfrom coppafisher.results import export_pciseq_unfiltered_dapi_image\n\nnb = Notebook(\"/path/to/notebook\")\nconfig_path = \"/path/to/config.ini\"\nexport_pciseq_unfiltered_dapi_image(nb, config_path, radius_norm_file=None)\n</code></pre> <p>You can set <code>radius_norm_file=\"default\"</code> to use the default dapi radius normalisation when the dapi channel is 0.</p> <p>The DAPI image can then be loaded into memory by</p> <pre><code>import numpy as np\n\ndapi_image = np.load(\"/path/to/dapi_image.npz\")[\"arr_0\"]\n</code></pre>"},{"location":"export/#gene-spots-export","title":"Gene spots export","text":"<p>Export gene spots into a compatible csv file by</p> <pre><code>from coppafisher import Notebook\nfrom coppafisher.results import export_to_pciseq\n\nnb = Notebook(\"/path/to/notebook\")\nexport_to_pciseq(nb, method)\n</code></pre> <p>where method can be <code>\"omp\"</code>, <code>\"prob\"</code>, or <code>\"anchor\"</code> for each gene calling method. To set a score and/or intensity minimum threshold:</p> <pre><code>from coppafisher import Notebook\nfrom coppafisher.results import export_to_pciseq\n\nnb = Notebook(\"/path/to/notebook\")\nexport_to_pciseq(nb, method, score_thresh, intensity_thresh)\n</code></pre> <p>score_thresh and intensity_thresh must be numbers. Use the Viewer to help decide on thresholds. intensity_thresh is set to <code>0.15</code> for OMP in the Viewer by default.</p>"},{"location":"export/#merge-cell-mask-chunks","title":"Merge cell mask chunks","text":"<p>Multiple cell masks for separate tiles can be merged together that are produced by cellpose. The cell masks must be uint16 3d images all of the same shape <code>(im_z, im_y, im_x)</code>. They must be saved as .npy files.</p> <pre><code>from coppafisher.results import merge_cell_masks\n\nmerged_cell_mask = merge_cell_masks(\n    cell_mask_file_paths=[\"/path/to/cell_mask_0.npy\", \"/path/to/cell_mask_1.npy\"],\n    cell_mask_origin_yxzs=[[0.0, 0.0, 0.0], [1100, 1.0, 0.0]],\n    expected_tile_overlap=0.15,\n    merge_cells_method=\"\",\n)\n</code></pre> <p>where <code>cell_mask_origin_yxzs</code> is the bottom-leftmost position for each cell mask in a global coordinate frame. For more details, see the <code>merge_cell_masks</code> docstring at <code>coppafisher/results/cell_mask.py</code>.</p> <p>If you have a coppafisher notebook, you can base the merging off the tile stitch results:</p> <pre><code>from coppafisher import Notebook\nfrom coppafisher.results import merge_cell_masks\n\nnb = Notebook(\"/path/to/notebook\")\nmerged_cell_mask = merge_cell_masks(\n    cell_mask_file_paths=[\"/path/to/cell_mask_0.npy\", \"/path/to/cell_mask_1.npy\"],\n    cell_mask_origin_yxzs=nb.stitch.tile_origin,\n    expected_tile_overlap=nb.stitch.associated_config[\"stitch\"][\"expected_overlap\"],\n    merge_cells_method=\"\",\n)\n</code></pre> Merging methods <p>There are two strategies for merging cell masks together:</p> <p>1) <code>merge_cells_method=\"\"</code> does no cell merging and the tile that has the closest tile centre to the overlapping pixel data is used. This can leave erroneous split cells at the midpoint between the tile overlap.</p> <p> No merging result. </p> <p>2) <code>merge_cells_method=\"merge 0.5\"</code> merges cells together in the overlapping region when the cells have at least 50% overlap. You can adjust the number 0.5 for anything between 0 and 1 to best suit your data. For more details on the merging method:</p> <pre><code>from coppafisher.results import merge_cell_masks\nprint(merge_cell_masks.__doc__)\n</code></pre> <p> Merging with a low overlap threshold. </p> <p> Merging with a high overlap threshold. </p> Saving the merged cell mask <p>You can save the resulting merged cell mask as a .npy file</p> <pre><code>import numpy as np\n\nnp.save(\"/path/to/merged_cell_mask.npy\", merged_cell_mask)\n</code></pre> <p>Or a compressed .npz file</p> <pre><code>import numpy as np\n\nnp.savez_compressed(\"/path/to/merged_cell_mask.npy\", merged_cell_mask)\n</code></pre>"},{"location":"export/#custom-images","title":"Custom Images","text":"<p>Additional custom images can be aligned with coppafisher images and gene spots provided that you have a dapi channel (or something similar to align with the anchor-DAPI image).</p>"},{"location":"export/#extract-the-additional-images","title":"Extract the additional image(s)","text":"<p>The additional images must be extracted from ND2 files. You will likely require the DAPI channel for best results. They are saved as tiff files. If you do not have ND2 input files, you need to first manually convert them to tiff files.</p> <pre><code>from coppafisher.custom_alignment import extract_raw\nfrom coppafisher import Notebook\n\nconfig_file = \"/path/to/used/config.ini\"\ncustom_nd2 = \"/path/to/input/file.nd2\"\noutput_dir = \"/path/to/extract/directory/\"\n\nnb = Notebook(\"/path/to/notebook\")\nextract_raw(\n    nb,\n    config_file,\n    save_dir=output_dir,\n    read_dir=custom_nd2,\n    use_tiles=nb.basic_info.use_tiles,\n    use_channels=[nb.basic_info.dapi_channel, 9, 23],\n    reverse_custom_z=False,\n    radius_norm_file=None,\n    radius_norm_channels=None,\n    dapi_radius_norm_file=None,\n)\n</code></pre> <p><code>use_channels</code> can be any valid channel(s) inside the custom image .nd2 file. This will also extract the anchor round in the DAPI channel. You can reverse the z planes in the custom image by setting <code>reverse_custom_z</code> to <code>True</code>.</p> <p>Set <code>radius_norm_file=\"default_nine\"</code> to use the default nine channel tile radius/channel normalisation file at <code>coppafisher/setup/nine_channel_normalisations.npz</code>.</p> <p>Set <code>radius_norm_file=\"default_seven\"</code> to use the default seven channel tile radius/channel normalisation file at <code>coppafisher/setup/seven_channel_normalisations.npz</code>.</p> <p>Set <code>dapi_radius_norm_file=\"default\"</code> to use the default dapi channel tile radius/channel normalisation file at <code>coppafisher/setup/dapi_channel_normalisations.npz</code>.</p> Config File <p>The config file must be a valid configuration, like the one used during the experiment. <code>input_dir</code> must be a real input directory.</p>"},{"location":"export/#stitch","title":"Stitch","text":"<p>The extracted raw anchor-DAPI images are stitched using coppafisher's stitch method. The custom image is stitched by the same method separately. This then needs to be registered with the anchor-DAPI in the next step. Do this for each custom image channel separately. I suggest starting with the dapi channels first</p> <pre><code>from coppafisher.custom_alignment import fuse_custom_and_dapi\n\nfused_custom_dapi_image, fused_anchor_dapi_image = fuse_custom_and_dapi(nb, output_dir, channel=nb.basic_info.dapi_channel)\n</code></pre>"},{"location":"export/#dapi-register","title":"Dapi Register","text":"<p>Alignment is done using the package <code>LineStuffUp</code> maintained by Max Shinn (m.shinn@ucl.ac.uk). This allows control over the type of transformation to apply based on their custom images. Install via pip</p> <pre><code>python -m pip install LineStuffUp\n</code></pre> <p>Then start the interactive alignment process</p> <pre><code>import linestuffup.gui\nfrom linestuffup.base import TranslateRotate\n\nround_transform = linestuffup.gui.alignment_gui(\n    fused_custom_dapi_image, fused_anchor_dapi_image, transform_type=TranslateRotate\n)\n</code></pre> <p>Press <code>Add new point</code> and click twice to place two corresponding points. Do this a few times, preferably in various z planes too. Press <code>Perform transform</code> to see the resulting transform. Once you are happy with the result, close the napari window.</p> Type of Transform <p>You can change the type of transform you wish to find, please see the transfrom readme for details.</p> <p>For example, you could use the more robust transform type of <code>TranslateRotateRescale</code>. It requires four points in every corner of the image on both edges of the z stack for best results.</p> Save and Load Transforms <p>Every transform can be saved and reloaded at a later point. You just need to save the text representation of the transform which can be found by</p> <pre><code>str(round_transform)\n</code></pre> <p>You can save it using Python</p> <pre><code>with open(\"/path/to/saved/transform.txt\", \"w\") as file:\n    file.write(str(round_transform))\n</code></pre> <p>It can be reloaded by</p> <pre><code>from linestuffup.base import *\n\nwith open(\"/path/to/saved/transform.txt\", \"r\") as file:\n    exec(\"round_transform = \" + \"\\n\".join(file.readlines()))\n</code></pre> <p>You can rename the variable from <code>round_transform</code> to anything.</p> <p>Do not run <code>exec</code> on stranger's code (it could be malicious)!</p> <p>You can now apply the resulting transform to the custom dapi image and save the result as a <code>.tif</code> file</p> <pre><code>import numpy as np\nimport tifffile\n\nfused_custom_dapi_image_transformed = round_transform.transform_image(\n    fused_custom_dapi_image, output_size=fused_anchor_dapi_image.shape, force_size=True, labels=True\n)\ntifffile.imwrite(\"/path/to/saved/custom_dapi_image_transformed.tif\", fused_custom_dapi_image_transformed)\ndel fused_custom_dapi_image_transformed\ndel fused_anchor_dapi_image\n</code></pre>"},{"location":"export/#non-dapi-register","title":"Non-Dapi Register","text":"<p>For a non-dapi custom image channel <code>c</code>, it is recommended to find a specific transform to move to the dapi channel for best registration. To do this, first find a transform to move into the dapi custom image's frame</p> <pre><code>from coppafisher.custom_alignment import fuse_custom_and_dapi\nimport linestuffup.gui\nfrom linestuffup.base import TranslateRotate\n\nfused_custom_channel_image, _ = fuse_custom_and_dapi(nb, output_dir, channel=c)\n\nchannel_transform = linestuffup.gui.alignment_gui(\n    fused_custom_channel_image, fused_custom_dapi_image, transform_type=TranslateRotate\n)\n</code></pre> <p>Now save the fully registered channel image</p> <pre><code>import tifffile\n\nfused_custom_channel_image_transformed = (channel_transform + round_transform).transform_image(\n    fused_custom_channel_image, output_size=fused_custom_channel_image.shape, force_size=True, labels=True\n)\ntifffile.imwrite(f\"/path/to/saved/custom_channel_{c}_image_transformed.tif\", fused_custom_channel_image_transformed)\ndel fused_custom_channel_image_transformed\ndel fused_custom_channel_image\n</code></pre>"},{"location":"find_spots/","title":"Find Spots","text":"<p>Spots are detected as local intensity maxima on the filtered images to create 3D point clouds. Spot positions are used later in register and call spots.</p>"},{"location":"find_spots/#0-auto-threshold","title":"0: Auto Threshold","text":"<p>For each tile (\\(t\\))/round (\\(r\\))/channel (\\(c\\)) image, an automatic intensity threshold (shortened to <code>auto_thresh</code>) is computed. This is done by taking all pixels on a single, central z plane on the filtered image called \\(I_{xy}\\). The <code>auto_thresh</code> is</p> \\[ \\text{auto\\_thresh}_{trc} = \\text{n}^{\\text{th}}\\text{ percentile}(|I|_{trcxy})_{trc..} \\times a \\] <p>where \\(|...|\\) is the absolute value of each element separately. The median is computed over all x and y values to give a scalar that is a good lower bound estimate for the random noise amplitude. \\(n\\) is the <code>auto_thresh_percentile</code> (typically \\(5\\)). \\(a\\) is the <code>auto_thresh_multiplier</code> (typically \\(160\\)). Higher <code>auto_thresh_multiplier</code> makes spot detection stricter.</p>"},{"location":"find_spots/#1-spot-detection","title":"1: Spot Detection","text":"<p>For each tile/round/channel filtered image (\\(I_{trcxyz}\\)), a 3D point cloud is created out of all points where</p> \\[ I_{trcxyz} &gt; \\text{auto\\_thresh}_{trc} \\]"},{"location":"find_spots/#2-remove-duplicates","title":"2: Remove Duplicates","text":"<p>Some of these points will be nearby or adjacent, representing the same spot multiple times. To deal with this, points are removed. For each point, an ellipsoid region of x/y radius <code>radius_xy</code> (typically \\(5\\)) and z radius <code>radius_z</code> (typically \\(2\\)) is considered. If one or more points are found within the point's ellipsoid region, then only the point with the greatest intensity is kept. If a point is isolated, it is kept. The process is repeated for all points.</p> <p>If too few spots are found for a tile/round/channel image, then a warning and/or error is raised to the user.</p>"},{"location":"find_spots/#diagnostics","title":"Diagnostics","text":""},{"location":"find_spots/#auto-threshold","title":"Auto Threshold","text":"<p>The calculated auto thresholds can be seen from the notebook. For tile <code>t</code>, round <code>r</code>, channel <code>c</code>, the <code>auto_thresh</code> value is saved as <code>float32</code> at</p> <pre><code>from coppafisher import Notebook\n\nnb = Notebook(\"/path/to/notebook\")\nnb.find_spots.auto_thresh[t, r, c]\n</code></pre>"},{"location":"find_spots/#detected-spots","title":"Detected Spots","text":"<p>A find spots viewer will help to understand the config parameters. Move sliders to adjust the find spots parameters and see the spot detection results. You can select any tile/round/channel combination. By default, the first tile's anchor round/channel is shown. To display the viewer, in the terminal</p> <pre><code>python -m coppafisher -fs /path/to/notebook\n</code></pre> <p>and open the link shown in the terminal on a modern browser to show and interact with the viewer. Press Ctrl + C in the terminal to close the viewer.</p> <p>Spot detection is most crucial for the anchor round/channel images. So, it is recommended to configure find spots parameters based on one of these images.</p>"},{"location":"glossary/","title":"Glossary","text":"<ul> <li> <p>Anchor round - A single round taken, usually on a chosen \"anchor channel\" that has a high Signal-to-Noise Ratio (SNR). All genes of interest are given the same fluorescing dye probe so that every spot lights up. The anchor round is essential for detecting all spots at once in the same microscope image.</p> </li> <li> <p>Background gene - Background genes refer to constant pixel intensity across all sequencing rounds in one channel. This is an indicator of an anomalous fluorescing artefact that is not a spot. No spot codes are made to be the same channel in all rounds. This way spots are not mistaken for background fluorescence and vice versa.</p> </li> <li> <p>Bled code - Every gene has a unique bled code. It is a series of intensities expected in each sequencing round/channel. Its bled code is dependent on the gene's gene code and the bleed matrix.</p> </li> <li> <p>Bleed matrix - How intense each dye is in each sequencing channel. This is estimated during the call spots stage.</p> </li> <li> <p>Channel - A combination of excitation light of a certain wavelength and specific emission filter. We use multiple channels to distinguish every dye colour (almost always the number of channels is equal to the number of unique dyes). But, a dye can have \"bleed through\", i.e. brightness in multiple channels from the same dye.</p> </li> <li> <p>DAPI - A dye that fluoresces the nuclei of all cells. It is used to register between sequencing rounds. The DAPI is also a background image in the Viewer.</p> </li> <li> <p>Gene code - A sequence of dyes that are assigned to a gene for each sequencing round. Each gene has a unique gene code. For example, if the dyes are labelled <code>0, 1, 2</code> and there are 2 sequencing rounds, some example gene codes are <code>0, 1</code> (i.e. dye <code>0</code> in first round, dye <code>1</code> in second round), <code>1, 2</code>, <code>0, 2</code>.</p> </li> <li> <p>Notebook - A write-once<sup>1</sup> compressed file that stores all important outputs from coppafisher. The notebook is used to plot many diagnostics. The notebook contains notebook pages. There is at least one notebook page for each method section. A notebook can be loaded by <code>from coppafisher import Notebook; nb = Notebook(\"path/to/notebook\")</code>. Variables from the notebook can be directly read. For example, you can read the <code>use_tiles</code> variable from the <code>basic_info</code> page by <code>print(nb.basic_info.use_tiles)</code>. Each variable has a description, which can be printed. For example, <code>nb.basic_info &gt; \"use_tiles\"</code>.</p> </li> <li> <p>OMP - Stands for Orthogonal Matching Pursuit. It is the final section of the coppafisher pipeline. It is coppafisher's most sophisticated algorithm for gene calling and is used as a way of untangling genes that overlap by assuming that the pixel intensity is a linear combination of each gene bled code. There is currently no reason to suspect that gene bled codes combine non-linearly.</p> </li> <li> <p>Point cloud - A series of spatial pixel positions. Typically used to represent detected spot positions during find spots.</p> </li> <li> <p>PSF - Stands for Point Spread Function and is used during image filtering. The Wiener deconvolution requires a PSF to remove blurring caused by frequencies with a low signal-to-noise ratio. See the filter overview and the Wikipedia article for more details.</p> </li> <li> <p>Sequencing round - An image of the tissue, made up of multiple tiles and sequencing channels. Before each imaging round, the tissue is treated with various solutions to remove the previous DNA probes and then hybridise new ones. Each spot will bind to a specific bridge probe which then binds to a fluorescing dye probe, causing it to fluoresce in specific channel(s). The colour of each spot in each round is dictated by its gene identity (identities) and their corresponding gene code(s).</p> </li> <li> <p>Spot - An amplified ball of DNA with a unique barcode specific to each gene. The gene can be determined by looking at the same spot in all sequencing rounds to reveal the gene code. Coppafisher takes the raw images of the spots as input and outputs the gene identity of each spot in situ.</p> </li> <li> <p>Tile - A cuboid subset of the microscope image of pixel size \\(n_z \\times n_y \\times n_x\\) in z, y, and x, where \\(n_y = n_x \\sim 2000 \\text{ pixels}\\). Typically, \\(n_z\\sim10\\text{s}\\). Usually, all adjacent tiles overlap by \\(10\\%-15\\%\\) to give coppafisher sufficient information to align tiles (see stitch for details).</p> </li> </ul> <ol> <li> <p>There are some cases of notebooks being \"rewritten\", see advanced usage.\u00a0\u21a9</p> </li> </ol>"},{"location":"migration/","title":"Migration","text":"<p>Almost all versions of coppafisher will automatically warn you about any incompatibilities when the pipeline is run on a new version. Below contains specific migration guides for special cases.</p>"},{"location":"migration/#coppafisher-leq-15-migration","title":"Coppafisher \\(\\leq\\) 1.5 Migration","text":"<p>The extraction directory (labelled <code>tile_dir</code> under the config) is deprecated. Update the directory by</p> <pre><code>from coppafisher.extract import update_tile_dir\n\nupdate_tile_dir(\"/path/to/config.ini\")\n</code></pre> <p>The notebook from versions &lt;= 1.5.0 will open as normal. The data can be zipped at any time to be the same as versions &gt; 1.5.0 by</p> <pre><code>from coppafisher import Notebook\n\nnb = Notebook(\"/path/to/notebook\")\nnb.zip()\n</code></pre> <p>You may be prompted to install the 7-zip CLI if it is not found.</p> Specify drive to zip from <p>By default, the default drive is used for zipping notebook variables (i.e. within <code>/tmp/...</code> on Linux). If you do not have sufficient disk space on this drive and wish to use a different location, specify your own existing temporary directory by doing</p> <pre><code>from coppafisher import Notebook\n\nnb = Notebook(\"/path/to/notebook\")\nnb.zip(\"/path/to/temporary/directory/\")\n</code></pre>"},{"location":"omp/","title":"Orthogonal Matching Pursuit (OMP)","text":"<p>OMP is coppafisher's current best gene assignment algorithm. OMP runs independently, except requiring register for image-alignment and call spots for dataset-accurate representation of each gene's unique barcode: its bled code, \\(\\mathbf{B}\\).</p> <p>A pixel score image is produced for every pixel and every gene by iterating through steps 2-4. Then, the final gene reads are found in step 5.</p>"},{"location":"omp/#definitions","title":"Definitions","text":"<ul> <li>\\(r\\) and \\(c\\) represents sequencing rounds and channels respectively.</li> <li>\\(B_{grc}\\) represents gene g's bled code in round \\(r\\), channel \\(c\\) saved at <code>nb.call_spots.bled_codes</code> from call spots.</li> <li>\\(S_{prc}\\) is pixel \\(p\\)'s colour in round \\(r\\), channel \\(c\\), after pre-processing is applied.</li> <li>\\(c_{pgi}\\) is the OMP pixel score given to gene \\(g\\) at pixel \\(p\\) on the \\(i\\)'th OMP iteration.</li> <li>\\(w_{pgi}\\) is the OMP gene weight given to gene \\(g\\) for image pixel \\(p\\) on the \\(i\\)'th iteration. This is computed by least squares in step 3. \\(i\\) takes values \\(1, 2, 3, ...\\)</li> <li>\\(||A||_{...}\\) represents an L2 norm of \\(A\\) (or Frobenius norm for a matrix) over all indices replaced by a dot (\\(.\\)).</li> </ul>"},{"location":"omp/#0-pre-processing","title":"0: Pre-processing","text":"<p>All pixel colours are gathered using the results from register. Any out of bounds round/channel colour intensities are set to zero. The pixel colours, \\(\\mathbf{S}\\), are multiplied by <code>nb.call_spots.colour_norm_factor</code> for the each tile.</p>"},{"location":"omp/#1-minimum-intensity-threshold","title":"1: Minimum Intensity Threshold","text":"<p>Before running on pixels, many pixels are discarded because they are background and not spots. To do this, we take the middle z plane colours for each tile, \\(D_{txyrc}\\), and compute their intensities as</p> \\[ I_{txy} = \\min_r(\\max_c(|D_{txyrc}|)) \\] <p>The intensity thresholds for each tile are then</p> \\[ \\text{minimum\\_intensity}_t = a\\times\\text{nth percentile}_{xy}(I_{txy}) \\] <p>\\(n\\) is the <code>minimum_intensity_percentile</code> (typically 5) and \\(a\\) is the <code>minimum_intensity_multiplier</code> (typically 6).</p>"},{"location":"omp/#2-next-gene-assignment","title":"2: Next Gene Assignment","text":"<p>A pixel can have more than one gene assigned to it. The most genes allowed on each pixel is <code>max_genes</code> (typically 5). Let's say we are on iteration \\(i\\) (\\(i = 1, 2, 3, ...\\)) for pixel \\(p\\). The pixel will already have \\(i - 1\\) genes assigned to it and their weights have been computed \\((w_{pg(i - 1)})\\). We compute the latest residual pixel colour \\(R_{prci}\\) as</p> \\[ R_{prci} = S_{prc} - \\sum_g(w_{pg(i - 1)}B_{grc}) \\] <p>For the first iteration, \\(R_{prc(i=1)} = S_{prc}\\). Using this residual, a \"semi dot product score\" is computed for every gene and background gene \\(g\\) similar to call spots</p> \\[ \\text{(gene scores)}_{pgi} = \\frac{1}{N_r}\\Bigg|\\sum_r\\Bigg(\\frac{1}{||\\mathbf{\\hat{R}}||_{pr.(i-1)}||\\mathbf{B}||_{gr.}}\\sum_{c}(\\hat{R}_{prc(i - 1)}B_{grc})\\Bigg)\\Bigg| \\] <p>where</p> \\[ \\hat{R}_{prci} = \\epsilon_{prci}^2R_{prci}\\text{,}\\space\\space\\space \\epsilon_{prci}^2 = N_r N_c\\frac{\\sigma_{pirc}^{-2}}{\\sum_{rc}\\sigma_{pirc}^{-2}} \\] <p>and</p> \\[ \\sigma_{pirc}^2 = \\beta^2 + \\alpha\\sum_{g\\text{ assigned}} w_{pg(i-1)}^2 B_{grc}^2\\text{,}\\space\\space\\space N_r = \\sum_r 1\\text{,}\\space\\space\\space N_c = \\sum_c 1 \\] <p>\\(\\alpha\\) is given by <code>alpha</code> (typically 120) and boosts the uncertainty on round-channel pairs already strongly weighted. \\(\\beta\\) is given by <code>beta</code> (typically 1) and gives every round-channel pair a constant uncertainty.</p> Why do we need an uncertainty weighting (\\(\\mathbf{\\epsilon}^2\\)) for each round-channel pair? <p>On real datasets, subtracting the assigned, weighted bled code is not perfect for every round (shown below). Therefore, \\(\\mathbf{\\epsilon}\\) is a way of estimating the uncertainty associated with the imperfect gene weights. It places a bias towards genes that are bright in unique round-channel pairs when \\(\\alpha&gt;0\\).</p> <p>By default, \\(\\alpha &gt;&gt; \\beta\\) so it is unlikely to assign two genes bright in the same round-channel pairs.</p> <p>If you fully trust the weightings to be accurate, set <code>alpha</code> to zero in the config.</p> <p> An example of OMP failing to find a scalar to correctly weight every bright round-channel pair for a   gene. It is failing because the residual colour is sometimes very positive and sometimes very negative. Only the   fourth round was almost perfectly subtracted. </p> <p>Gene \\(\\tilde{g}\\) is successfully assigned to pixel \\(p\\) when all conditions are met:</p> <ul> <li>\\((\\text{gene scores})_{p\\tilde{g}i}\\) is the largest scoring gene.</li> <li>\\((\\text{gene scores})_{p\\tilde{g}i} &gt;\\) <code>dot_product_threshold</code> (typically 0.72).</li> <li>\\(\\tilde g\\) is not already assigned to the pixel.</li> <li>\\(\\tilde g\\) is not a background gene.</li> <li>The residual intensity \\(\\min_r(\\max_c(|\\hat{R}_{prci}|)) &gt; \\text{minimum\\_intensity}_t\\). See diagnostic.</li> <li>Iteration \\(i \\leq\\) <code>max_genes</code>.</li> </ul> <p>The reasons for each of these conditions is to:</p> <ul> <li>pick the best gene</li> <li>remove unconfident gene reads</li> <li>not double assign genes</li> <li>avoid over-fitting on high-background pixel colour</li> <li>remove dim colours (background noise)</li> <li>avoid assigning too many genes</li> </ul> <p>respectively. If a pixel fails to meet one or more of these conditions, then no more genes are assigned to it and the pixel scores will be final.</p> <p>If pixel \\(p\\) meets all conditions, then gene \\(\\tilde g\\) is taken as the next gene assigned.</p> <p>If all remaining pixels fail the conditions, then the iterations stop and the current pixel scores \\(\\mathbf{c}\\) are kept as final for step 5.</p>"},{"location":"omp/#3-gene-weights","title":"3: Gene Weights","text":"<p>On each iteration, the gene weights are re-computed for all genes assigned to pixel \\(p\\) to best represent the pixel's colour. All unassigned genes have a zero weight, so \\(g\\) here represents only the assigned genes (\\(i\\) assigned genes) for pixels that passed step 2. The weights, \\(w_{pgi}\\), are computed through the method of least squares by minimising the scalar residual</p> \\[ \\sum_{rc}(S_{prc} - \\sum_{g\\text{ assigned}}(B_{grc}w_{pgi}))^2 \\] <p>In other words, using matrix multiplication, the weight vector of length genes assigned is</p> \\[ \\mathbf{w} = \\bar{\\mathbf{B}}^{-1} \\bar{\\mathbf{S}} \\] <p>where \\(\\bar{(...)}\\) represents flattening the round and channel dimensions into a single dimension, so \\(\\bar{\\mathbf{B}}\\) is of shape \\(\\text{genes assigned}\\) by \\(\\text{rounds}*\\text{channels}\\) and \\(\\bar{\\mathbf{S}}\\) is of shape \\(\\text{rounds} * \\text{channels}\\). \\((...)^{-1}\\) is the Moore-Penrose matrix inverse (a pseudo-inverse).</p>"},{"location":"omp/#4-pixel-scores","title":"4: Pixel Scores","text":"<p>After updating the gene weights, every assigned gene pixel score is (re)computed for pixels that passed gene assignment. The pixel score for assigned gene \\(g\\) in pixel \\(p\\) is given by</p> \\[ c_{pgi} = \\frac{1}{N_r ||\\mathbf{\\tilde{R}}||_{pgr.i}}\\Bigg | \\sum_{rc}\\tilde{R}_{pgrci} \\hat{B}_{grc} \\Bigg | \\] <p>where</p> \\[ \\tilde{R}_{pgrci} = \\epsilon_{prci}^2\\Bigg( S_{prc} - \\sum_{g'\\text{; }g' \\neq g}B_{g'rc}w_{pg'i}\\Bigg) \\] <p>and</p> \\[ \\epsilon_{pgrci}^2 = N_r N_c \\frac{\\sigma_{pgirc}^{-2}}{\\sum_{rc} \\sigma_{pgirc}^{-2}} \\text{,}\\space\\space\\space \\sigma_{pgirc}^2 = \\beta^2 + \\alpha \\sum_{g'\\text{; }g' \\neq g}w_{pg'i}^2 B_{g'rc}^2 \\] <p>A pixel score is made negative if the gene's weight is negative.</p> <p>Step 2 is now repeated on the remaining pixels.</p> Why not use the scores from step 2 as the pixel scores? <p>If you recall, from step 2, the assigned gene is given a preliminary score similar to step 4's pixel score. This score is not used as the final OMP pixel scores (but, we did try). This is because the pleminary score has lowered the scores because they overlap with other genes. In other words, the scores are lowered by brightness in other rounds-channel pairs.</p> <p>The step 4 scoring method gets around this. Assuming that all gene assignments are perfect, by subtracting those assignments off except gene g, then gene g is given a fairer chance of scoring highly, hopefully without the brightness of other genes.</p>"},{"location":"omp/#5-spot-scoring-and-spot-detection","title":"5: Spot Scoring and Spot Detection","text":"<p>The gene pixel score images are converted to gene score images by convolving with the mean spot given as a numpy .npy file at file path <code>omp_mean_spot</code> in the <code>file_names</code> config section. If <code>omp_mean_spot</code> is not given, the default mean spot is used (shown below). The mean spot is divided by its sum then used. This gives a score for every pixel for every gene. Spot-shaped and high pixel score regions result in higher score maxima. Scores can be \\(\\geq 0\\). But, in practice, scores are rarely greater than \\(1\\).</p> The default mean spot. The middle image is the central z plane. <p>Using the score images, each gene's spots are detected using the find spots algorithm to find score local maxima using config parameters <code>radius_xy</code> (typically <code>3</code>) and <code>radius_z</code> (typically <code>2</code>) respectively with a score threshold set by <code>score_threshold</code> (typically <code>0.1</code>). These are the final OMP gene reads shown in the Viewer.</p> Why not score each spot using a single pixel score value? <p>Pixel scores can be inflated by single overly-bright round/channel anomalies since they are computed using a non-robust least squares calculation. This could be from real autofluorescence or from mistakes in registration. For this reason, a spot's score is better represented by using pixel score data from its neighbourhood. The mean spot is an estimation of how much care to put in the local, spatial neighbourhood.</p> <p>If you still wanted to score each spot by a single pixel score value, create your own 1x1x1 mean spot with value \\(&gt;0\\) and run OMP again.</p>"},{"location":"omp/#diagnostics","title":"Diagnostics","text":""},{"location":"omp/#intensity","title":"Intensity","text":"<p>It is recommended to view the pixel intensities on a histogram first by typing</p> <pre><code>from coppafisher import Notebook\nfrom coppafisher.plot import intensity\n\nnb = Notebook(\"/path/to/notebook\")\nintensity.view_intensity_histogram(nb)\n</code></pre> <p>On this plot, you can see vertical lines to indicate important intensity values.</p> <p>Use the diagnostic to see intensity images. Once OMP is complete, you can view the minimum intensity computed for each tile by doing</p> <pre><code>from coppafisher import Notebook\n\nnb = Notebook(\"/path/to/notebook\")\nprint(nb.omp.results[f\"tile_{tile}\"].attrs[\"minimum_intensity\"])\n</code></pre> <p>where <code>tile</code> is the tile index.</p>"},{"location":"omp/#viewer","title":"Viewer","text":"<p>Use the Viewer to check the final gene reads made by OMP.</p>"},{"location":"omp/#pdf","title":"PDF","text":"<p>Check the <code>_omp.pdf</code> file created at runtime in the output directory for details on the OMP mean spot, the spot score distributions, gene counts, and gene locations.</p>"},{"location":"overview/","title":"Overview","text":"<p>The coppafisher pipeline is separated into distinct sections. Some of these are for image pre-processing (extract, filter), image alignment (register, stitch) and spot detection/gene calling (find spots, call spots, orthogonal matching pursuit). Below, each stage is given in chronological order. For full detail on each pipeline section, click on a stage on the left panel.</p>"},{"location":"overview/#extract","title":"Extract","text":"<p>All raw data is re-saved at the <code>tile_dir</code> in the <code>file_names</code> config section. Coppafisher does this to:</p> <ul> <li>Compress data.</li> <li>Remove unused tiles, rounds, and channels that may be in the given raw files.</li> <li>Save the raw data in a consistent format.</li> <li>Allow for faster data reading by using zarr arrays.</li> </ul> <p>Extract also saves metadata inside of the <code>tile_dir</code> directory if the raw files are ND2 format.</p>"},{"location":"overview/#filter","title":"Filter","text":"<p>First, each tile is optionally divided by a radius/channel-dependent normalisation. The normalisation is given by <code>channel_radius_normalisation_filepath</code> file path to a .npz file inside the <code>filter</code> config section.</p> <p>Extract images are then filtered to minimise scattering of light/de-blur (bright points will appear as cones initially, hence the name \"Point Spread Function\") and emphasise spots. A given point spread function is used to Wiener deconvolve the images.</p> <p>The point spread function is given as a .npz file called <code>psf</code> under the <code>file_names</code> config section. The default is at <code>coppafisher/setup/default_psf.npz</code> . Filtering is also affected by <code>wiener_constant</code> inside the <code>filter</code> config section.</p> <p>After filtering is applied, the images are saved to the notebook as <code>float16</code> compressed zarr arrays.</p>"},{"location":"overview/#find-spots","title":"Find spots","text":"<p>Point clouds (a series of spot x, y, and z locations) are generated for each filtered image. These are found by detecting local maxima in image intensity around the rough spot size (specified by config variables <code>radius_xy</code> and <code>radius_z</code> in the <code>find_spots</code> section). If two local maxima are the same value and in the same spot region, then one is chosen at random. Warnings and errors are raised if there are too few spots detected in a round/channel, these can be customised, see <code>find_spots</code> section in the config default file for variable names.</p>"},{"location":"overview/#register","title":"Register","text":""},{"location":"overview/#stitch","title":"Stitch","text":""},{"location":"overview/#call-spots","title":"Call spots","text":"<p>Ideally, every dye would express itself in a single, unique channel. In reality, dyes can express themselves in many channels, including the same channels as other dyes. A preliminary guess of the dye expression is used, but call spots improves these initial guesses by using high quality spots found in find spots in the anchor round/channel.</p> The bleed matrix throughout call spots, moving from left to right. <p>We also expect different genes to vary in brightness across both rounds and channels. Two reasons are:</p> <ul> <li>Bridge probes attach to gene spots where an RCP has been produced. The concentration of bridge probes that attach (and hence the brightness of the dye that attaches) can vary.</li> <li>Microscope software can automatically adjust exposure or expand the data to fill the uint16 range for each round/channel image separately. This equates to an unknown scale factor for each tile/round/channel that must be found.</li> </ul> <p>Therefore, call spots learns scale factors for each tile, round, and channel image as well as updating the gene bled codes for each round and channel.</p>"},{"location":"overview/#orthogonal-matching-pursuit","title":"Orthogonal Matching Pursuit","text":"<p>Orthogonal Matching Pursuit (OMP) is the most sophisticated gene calling method used by coppafisher, allowing for overlapping genes to be detected. It is an iterative, greedy algorithm that runs on individual pixels of the images. At each OMP iteration, a new gene is assigned to the pixel. OMP is also self-correcting. \"Orthogonal\" refers to how OMP will re-compute every gene contribution (their pixel score) after each iteration by least squares. Background genes are considered valid genes in OMP. The iterations stop if:</p> <ul> <li>Iteration number <code>max_genes</code> in the <code>omp</code> config section is reached.</li> <li>Assigning the next best gene to the pixel does not have a score above <code>dot_product_threshold</code> in the <code>omp</code> config.</li> <li>The next best gene is a background gene or already assigned to the pixel.</li> <li>Its residual colour is too dim.</li> </ul> <p>Pixel spot scores are computed by a convolution of the pixel score image with a mean spot. The mean spot is specified by the .npy file at <code>omp_mean_spot</code> in <code>file_names</code> config section. If it is not specified, a default mean spot is used, shown here. This gives every gene a score image for every pixel. The final OMP spots are then taken as local maxima on the pixel score image greater than <code>score_threshold</code>.</p>"},{"location":"register/","title":"Registration","text":"<p>The register section is the part of the pipeline concerned with aligning different rounds and channels. This is crucial for decoding spot colours into genes in the Call Spots and OMP sections. The aim of this section is to find a function \\(g_{trc}(\\mathbf{x})\\) for each tile, round and channel that takes in a location \\(\\mathbf{x}\\) on the anchor image for tile \\(t\\) and returns the corresponding location in round \\(r\\), channel \\(c\\) of the same tile. Since registration is done independently for each tile and we are often only working on one tile, we sometimes omit the subscript \\(t\\) in this documentation.</p> <p>Once we have these transformations \\(g\\), we can get a \\(n_{\\textrm{rounds}} \\times n_{\\textrm{channels}}\\) spot colours matrix \\(\\boldsymbol{F}(\\mathbf{x})\\) for each location \\(\\mathbf{x}\\) in the anchor image of a given tile via</p> \\[ \\boldsymbol{F}(\\mathbf{x}) = \\begin{pmatrix} f_{0, 0}(g_{0, 0}(\\mathbf{x})) &amp; \\cdots &amp; f_{0, n_c}(g_{0, n_c}(\\mathbf{x})) \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ f_{n_r, 0}(g_{n_r, 0}(\\mathbf{x})) &amp; \\cdots &amp; f_{n_r, n_c}(g_{n_r, n_c}(\\mathbf{x})) \\\\ \\end{pmatrix}, \\] <p>where \\(f_{rc}(\\mathbf{x})\\) is the intensity of round \\(r\\), channel \\(c\\) at location \\(\\mathbf{x}\\) in round \\(r\\), channel \\(c\\) coordinates. Note that even a single poorly aligned round or channel makes this matrix difficult to decode, which highlights the importance of this section.</p>"},{"location":"register/#high-level-overview","title":"High Level Overview","text":"<p>We need to consider a few questions when building the register pipeline. Some of the most important are:</p> <ol> <li> <p>How large should our search space of functions for \\(g\\) be? Are these functions independent between rounds and channels?</p> </li> <li> <p>How will we actually search this space?</p> </li> </ol>"},{"location":"register/#1-choosing-the-function-space","title":"1. Choosing the Function Space","text":"<p>To choose the set of functions we will use to fit to our data, we need to look for all sources of misalignment. Channel misalgnments are caused by:</p> <ul> <li> <p>The multiple camera setup, meaning channels belonging to different cameras are often slightly shifted or rotated with respect to one another.</p> </li> <li> <p>Chromatic aberration, the variable frequency-dependent dispersal of light through the lens. This expands the images from different channels by different amounts. See the figure below.</p> </li> </ul> <p>So the channel-to-channel differences are composed of shifts, rotations and scalings. We model each channel transform by an affine transform \\(A_c\\).</p> <p> An example of chromatic aberration. </p> <p>For round to round differences, we see much less predictable variability. Misalignments arise due to:</p> <ul> <li> <p>Tissue expansion in \\(z\\) throughout the rounds,</p> </li> <li> <p>Global shifts arising from movement of the stage,</p> </li> <li> <p>Variable local shifts due to the microfluidics system,</p> </li> <li> <p>Variable local shifts due to gravity or tissue deformation. These shifts have the potential to affect regions very differently. For example, the pyramidal layer is very densely packed and seems to sink more than surrounding areas, leading to different z-shifts in its vicinity. We have also observed rips within tissue samples, which cause different sides of the tissue to move in apart from each other in opposite directions.</p> </li> </ul> <p>The conclusion is that affine transformations do not sufficiently capture the richness of round-to-round transformations. We therefore allow for completely arbitrary transformations \\(\\mathcal{F}_r\\) for each round \\(r\\).</p> Affine Transform Failure Example <p>The figure below shows a rip in the tissue and the resulting misalignment in the DAPI channel. This is just one example of a misalignment that cannot be captured by an affine transform. <p> A rip in the tissue and two attempts at affine registration.  </p></p> <p>To answer the second part of question 1 - empirically, it seems we don't need to find \\(n_{\\textrm{rounds}} \\times n_{\\textrm{channels}}\\) independent transforms per tile, we only need \\(n_{\\textrm{rounds}} + n_{\\textrm{channels}}\\). Explicitly, we model every transform as</p> \\[  g_{rc}(\\mathbf{x}) = A_{c}(\\mathcal{F}_{r}(\\mathbf{x})). \\]"},{"location":"register/#2-computing-the-transforms","title":"2. Computing the Transforms","text":"<p>The round transforms are computed with Optical Flow, while the channel transforms are computed with Iterative Closest Point. For further details see the sections below.</p> Note on Affine Transforms <p>When we compute the round transforms \\(\\mathcal{F}_r\\) these often include some systematic error, like a small shift of 1 pixel and slight underestimation of the z-expansion. This is due to</p> <ul> <li> <p>downsampling of the images used to compute the optical flow transforms,</p> </li> <li> <p>A failure to find good shifts at z-boundaries, due to poor quality images in these planes.</p> </li> </ul> <p>To get around this, we find an affine correction \\(B_r\\) for each round. This means our functions \\(g_{rc}\\) can be written as</p> \\[ g_{rc}(\\mathbf{x}) = A_{c}(B_{r}(\\mathcal{F}_{r}(\\mathbf{x})). \\] <p>We combine the two affine transforms \\(A_c\\) and \\(B_r\\) to give us the simple formula</p> \\[ g_{rc}(\\mathbf{x}) = A_{rc}(\\mathcal{F}_{r}(\\mathbf{x})), \\] <p>which means that in practice our affine maps actually depend on round as well as channel.</p>"},{"location":"register/#optical-flow","title":"Optical Flow","text":"<p>We use optical flow to align the anchor DAPI \\(D_{r_{\\textrm{ref}}}(\\mathbf{x})\\)  to the round \\(r\\) DAPI \\(D_r(\\mathbf{x})\\). The output of this algorithm is a function \\(\\mathcal{F}_r\\) which satisfies the relation</p> \\[ D_{r_{\\textrm{ref}}}(\\mathcal{F}_r(\\mathbf{x})) = D_r(\\mathbf{x}). \\]"},{"location":"register/#1-how-does-it-work","title":"1. How does it work?","text":"<p>Suppose we have 2 images \\(I\\) and \\(J\\) which we'd like to register. This means for each position \\(\\mathbf{x}\\) in image \\(J\\) we would like to find the shift \\(\\mathbf{s}\\) satisfying</p> \\[ I(\\mathbf{x} + \\mathbf{s}) = J(\\mathbf{x}). \\] <p>Assuming that this \\(\\mathbf{s}\\) is small and that the function \\(I\\) is sufficiently smooth, we can approximate it by a linear function in this neighbourhood. Taylor expanding and rearranging yields:</p> \\[ \\mathbf{s} \\cdot \\boldsymbol{\\nabla} I(\\mathbf{x}) \\approx J(\\mathbf{x}) -  I(\\mathbf{x}), \\] <p>which is called the flow equation, an under-determined equation due to the fact that there are 3 unknowns - each component of \\(\\mathbf{s}\\).</p> <p>There are many different methods that exist to tackle this. The one we use is called the Lucas-Kanade method, which assumes that all pixels in a small window of radius \\(r\\) (the <code>window_radius</code> parameter with default value 8) around the point \\(\\mathbf{x}\\) have the same shift \\(\\mathbf{s}\\).</p> <p>Since this method assumes that all pixels have the same shift within this window, the condition that \\(I\\) is smooth is very important, as we need to ensure that the same flow equation holds for all \\(x\\) in the window. For this to be true, the Hessian \\(\\frac{\\partial ^2 I}{\\partial \\mathbf{x}^2}\\) cannot be too large in this window.</p> <p>Lucas-Kanade works as follows. Let \\(\\mathbf{x}_1, \\cdots, \\mathbf{x}_n\\) be all the points in this window. Then assuming these all have the same shift \\(\\mathbf{s}\\), we can gather the \\(n\\) flow equations</p> \\[ \\begin{pmatrix} \\boldsymbol{\\nabla} I(\\mathbf{x}_1)^T \\\\ \\vdots \\\\ \\boldsymbol{\\nabla} I(\\mathbf{x}_n)^T  \\end{pmatrix} \\mathbf{s} = \\begin{pmatrix} J(\\mathbf{x}_1) - I(\\mathbf{x}_1) \\\\ \\vdots \\\\ J(\\mathbf{x}_n) - I(\\mathbf{x}_n)  \\end{pmatrix}, \\] <p>which is now overdetermined! This is a better problem to have though, as the solution can be approximated by least squares.</p> <p>The above derivation makes the following assumptions</p> <ol> <li> <p>The shift \\(\\mathbf{s}\\) is small,</p> </li> <li> <p>The images are smooth. Ie, the Hessian \\(\\frac{\\partial ^2 I}{\\partial \\mathbf{x}^2}\\) is not too large,</p> </li> <li> <p>The images \\(I\\) and \\(J\\) have the same intensities, so that \\(I(\\mathbf{x} + \\mathbf{s}) = J(\\mathbf{x})\\).</p> </li> </ol> <p>To make sure we meet the assumptions we carry out the following steps:</p> <ol> <li> <p>Shift size:</p> <ul> <li> <p>We apply an initial Phase Correlation to find any global shift \\(\\mathbf{\\tilde{s}}\\) between \\(I\\) and \\(J\\), and shift \\(I\\) by this amount: \\(I(\\mathbf{x}) \\mapsto I(\\mathbf{x} - \\mathbf{\\tilde{s}})\\). Only once this is done do we carry out optical flow. This way, optical flow only captures the deviations from the global shift \\(\\mathbf{\\tilde{s}}\\).</p> </li> <li> <p>We downsample the images \\(I\\) and \\(J\\) in \\(y\\) and \\(x\\) before registration, which reduces the relative size of the shift.</p> </li> <li> <p>The implementation we use takes an iterative approach, meaning that after the initial flow field is found the algorithm runs again until some stopping criterion is met.</p> </li> </ul> </li> <li> <p>Smoothness:</p> <ul> <li>For practical reasons (speed and shift size), we need to downsample the images by a factor in \\(y\\) and \\(x\\) before registering. We perform the downsampling by taking the mean within each 4 by 4 sub-block as opposed to just extracting every 4th pixel in \\(y\\) and \\(x\\). This increases smoothness, as shown below.</li> <li>We smooth the images with a small Gaussian blur before registering. This needs to be done carefully because too much blurring decreases the resolution of the images and therefore the quality of the registration.</li> </ul> </li> <li> <p>To ensure we have similar intensity profiles we match the means of \\(I\\) and \\(J\\) in similar spatial locations.</p> </li> </ol> Smoothing Example <p>The figures below shows the effect of downsampling and blurring on the images. The Hessian determinants are shown on the right of the images.</p> Nearest Neighbour DownsamplingMean Sub-Block DownsamplingMean Sub-Block Downsampling + Gaussian <p><p> </p></p> <p><p> </p></p> <p><p> </p></p>"},{"location":"register/#2-practical-considerations","title":"2. Practical Considerations","text":""},{"location":"register/#speed","title":"Speed","text":"<p>Speed is an issue with this algorithm, because it needs to be run independently on so many pixels. We take the following steps to optimise it:</p> <ol> <li> <p>As mentioned above, we downsample the images in \\(y\\) and \\(x\\). The amount of donwsampling is controlled by the config parameter <code>sample_factor_yx</code> which has default value 4 in both directions, meaning that the algorithm runs 16 times faster than it would without downsampling.</p> </li> <li> <p>We split the downsampled images into 16 subvolumes (4 in \\(y\\) and 4 in \\(x\\)), and run optical flow in parallel on all of these independent subvolumes. The number of cores used can be adjusted by changing the <code>flow_cores</code> parameter though if left blank this will be computed automatically.</p> </li> </ol>"},{"location":"register/#interpolation","title":"Interpolation","text":"<p>As mentioned previously, the algorithm assumes that the images have the same intensities. This condition is certainly satisfied near cell nuclei, where similar features exist in both images. Far from nuclei though, where all we have is noise, the 2 images have completely independent intensities. The result of this is that our flow fields tend to only give reliable results near nuclei, as shown below.</p> <p>  The shifts found by optical flow are only reliable in a small window around cell nuclei. </p> <p>This is problematic, as a lot of our reads are found in between cell nuclei! We need to interpolate the values in these regions.</p>"},{"location":"register/#hard-threshold-interpolation","title":"Hard Threshold Interpolation","text":"<p>Suppose we have a flow field \\(\\mathcal{F}\\) that we would like to interpolate. We might go about it in the following way:</p> <ol> <li> <p>Choose some locations \\(\\mathbf{x}_1, \\cdots, \\mathbf{x}_n\\) where we know the shifts computed \\(\\mathbf{s}_1, \\cdots, \\mathbf{s}_n\\) are reliable,</p> </li> <li> <p>Define the interpolated flow to be of the form</p> </li> </ol> \\[ \\mathcal{F}_{\\textrm{interp}}(\\mathbf{x}) = \\sum_i w(\\mathbf{x}, \\mathbf{x}_i) \\mathbf{s}_i , \\] <p>where the sum is over all sample points \\(\\mathbf{x}_1, \\cdots, \\mathbf{x}_n\\), and the weights \\(w(\\mathbf{x}, \\mathbf{x}_i)\\) have the following properties:</p> <ul> <li> <p>\\(\\sum_i w(\\mathbf{x}, \\mathbf{x}_i) = 1\\) for all \\(\\mathbf{x},\\)</p> </li> <li> <p>\\(w(\\mathbf{x}, \\mathbf{x}_i)\\) is a decreasing function in \\(||\\mathbf{x}||\\) and \\(w(\\mathbf{x}_i, \\mathbf{x}_i) \\approx 1.\\)</p> </li> </ul> <p>If these 2 properties are met then \\(\\mathcal{F}_{\\textrm{interp}}\\) will be a weighted average of all the shifts \\(\\mathbf{s}_i\\), and since the weights are decreasing, the value of the \\(\\mathcal{F}_{\\textrm{interp}}\\) at each interpolation point \\(\\mathbf{x}_i\\) will be strongly weighted toward \\(\\mathbf{s}_i\\).</p> <p>Do such weight functions exist? Can we construct them? Yes and yes! Define the function</p> \\[ K(\\mathbf{x}, \\mathbf{y}) = \\exp \\Bigg( -\\frac{1}{2 \\sigma^2} ||\\mathbf{x} - \\mathbf{y}||^2 \\Bigg), \\] <p>then we can define the weights by</p> \\[ w(\\mathbf{x}, \\mathbf{x}_i) = \\dfrac{K(\\mathbf{x}, \\mathbf{x}_i)}{\\sum_j K(\\mathbf{x}, \\mathbf{x}_j)}. \\] <p>It is easy to see that this satisfies both the desired properties for the weights.</p> How to choose \\(\\sigma\\)? <p>In the limits:</p> <ul> <li> <p>as \\(\\sigma \\to 0\\) this tends to nearest neighbour interpolation,</p> </li> <li> <p>as \\(\\sigma \\to \\infty\\) the image takes the same value everywhere, the mean of the flow image at the sample points.</p> </li> </ul> <p>Another way of saying this is that as \\(\\sigma\\) grows, so does the radius of contributing pixels.</p> <p>We expect the shifts to vary more quickly in \\(z\\) than in \\(xy\\), so we have a different parameter for the blurring in each direction: <code>smooth_sigma</code>. This takes default values <code>[10, 10, 5]</code> (\\(y\\), \\(x\\) and \\(z\\)).</p>"},{"location":"register/#extension-to-soft-threshold-interpolation","title":"Extension to Soft Threshold Interpolation","text":"<p>The above method works well, but having a hard threshold means that some points \\(\\mathbf{x}_1, \\cdots, \\mathbf{x}_n\\) are used while others are completely ignored. This can lead to undersampling. A better approach is to employ a soft threshold, where we use all points \\(\\mathbf{x}_i\\) in the flow image but weight their contributions by the quality of the match at \\(\\mathbf{x}_i\\), which we will call \\(\\lambda(\\mathbf{x}_i)\\).</p> <p>This results in an interpolation of the form</p> \\[ \\mathcal{F}_{\\textrm{interp}}(\\mathbf{x}) = \\sum_i \\lambda(\\mathbf{x}_i) w(\\mathbf{x}, \\mathbf{x}_i) \\mathbf{s}_i , \\] <p>where the sum now ranges over all points in the image, and the weight functions are given by</p> \\[ w(\\mathbf{x}, \\mathbf{x}_i) = \\dfrac{K(\\mathbf{x}, \\mathbf{x}_i)}{\\sum_j \\lambda(\\mathbf{x}_j) K(\\mathbf{x}, \\mathbf{x}_j)}. \\] Definition of the Score \\(\\lambda\\) <p>Define the auxilliary score</p> \\[ \\eta(\\mathbf{x}) = D_{r_{\\textrm{ref}}}(\\mathcal{F}_r(\\mathbf{x}))D_r(\\mathbf{x}). \\] <p>Then our score \\(\\lambda\\) is defined as</p> \\[ \\lambda(\\mathbf{x}) = C_{0,1}\\bigg( \\dfrac{\\eta(\\mathbf{x}) - \\eta_0}{\\eta_1 - \\eta_0} \\bigg), \\] <p>where \\(\\eta_0\\) and \\(\\eta_1\\) are the 25th and 99th percentiles of \\(\\eta\\) respectively and \\(C_{a, b}\\) is the clamp function.</p> <p>This results in a score of 0 for common low intensity background regions, and 1 for high quality regions like cell nuclei.</p>"},{"location":"register/#extrapolation-in-z","title":"Extrapolation in z","text":"<p>The quality of the z-shifts drops rapidly towards the top end of the z-stack, because the optical flow uses windows of fixed radius (the <code>window_radius</code> parameter, which has default value 8). When these windows go over the edge of the image, the shifts get biased towards 0. This problem is made worse when the initial shift found is large in \\(z\\), as then the adjusted image is padded with many zeros.</p> <p>We get around this problem by linearly predicting the z-shifts from the bottom and middle of the image and replacing all z-shifts with these linear estimates. This is illustratedc in the figure below.</p> <p> Interpolation of x-y shifts, and extrapolation of z-shifts.  </p>"},{"location":"register/#iterative-closest-point","title":"Iterative Closest Point","text":"<p>We now attempt to find the affine corrections to the flows found earlier. As mentioned previously, this will be an affine transform for each tile \\(t\\), round \\(r\\) and channel \\(c\\). Furthermore, it will be separated into 2 transforms:</p> <ul> <li> <p>A round transform \\(B_{r}\\) which corrects for any errors in the flow \\(\\mathcal{F}_r\\),</p> </li> <li> <p>A channel transform \\(A_{c}\\) which corrects for all sources of the channel to channel variability.</p> </li> </ul> <p>We have omitted the tile subscript, but keep in the back of your mind that these transforms vary between tiles.</p>"},{"location":"register/#1-how-does-it-work_1","title":"1. How does it work","text":"<p>Optical flow took in 2 images (\\(I\\) and \\(J\\) ) as inputs and returned 3 images of the same size as outputs (the flow in each direction \\(y\\), \\(x\\) and \\(z\\)). ICP differs in that it takes in 2 point-clouds as input and returns an affine transform \\(A\\) as output.</p> <p>Let \\(X = \\begin{pmatrix} \\mathbf{x}_1, \\cdots,  \\mathbf{x}_m \\end{pmatrix}\\) be the base point cloud and \\(Y = \\begin{pmatrix} \\mathbf{y}_1, \\cdots,  \\mathbf{y}_n \\end{pmatrix}\\)  be the point cloud we are trying to match this to.</p> <p>In our case \\(X\\) is the set of anchor points and \\(Y\\) is the set of points in a given round and channel. So for every point \\(\\mathbf{y}_i\\) in \\(Y\\), we expect there to be a corresponding point \\(\\mathbf{x}_{\\beta(i)}\\) in \\(X\\) (the converse is not true). Estimating the matching \\(\\beta\\) between base and target points is the main difficulty in ICP. Some common methods to estimate this matching include:</p> <ol> <li> <p>We let \\(\\mathbf{x}_{\\beta(i)}\\) be the closest point from \\(X\\) to the point \\(\\mathbf{y}_i\\),</p> </li> <li> <p>The same as 1. but if there is no point in \\(X\\) within a certain radius \\(r\\) of \\(\\mathbf{y}_i\\) we don't bother to find a match,</p> </li> <li> <p>The same as 2. but we allow different radii in \\(y\\), \\(x\\) and \\(z\\). This is useful if we have some prior that the misalignment affects \\(y\\) and \\(x\\) more than \\(z\\), as we typically do.</p> </li> <li> <p>The same as 1. but we remove outliers where the shift \\(\\mathbf{y}_i -  \\mathbf{x}_{\\beta(i)}\\) seems to be very different from others in its vicinity.</p> </li> </ol> <p>We use approach 3. The parameters config parameters <code>neighb_dist_thresh_yx</code> and <code>neighb_dist_thresh_z</code> refer to \\(r_{yx}\\) and \\(r_z\\) respectively.</p> Setting \\(r_z\\) too low <p>Currently we think that ICP is correcting \\(y\\) and \\(x\\) more than \\(z\\), so we have \\(r_{z} &lt; r_{xy}\\). If this changes in the future (for example, if optical flow is not sufficiently capturing the variable z-shifts) then increasing \\(r_z\\) will allow ICP to have greater impact on the \\(z\\) transforms.</p> <p>Once we have a matching \\(\\beta\\), ICP works by finding an affine map \\(A\\) minimising the loss function</p> \\[ L(A) = \\sum_{i} || A \\mathbf{x}_{\\beta(i)} - \\mathbf{y}_i ||^2, \\] <p>(where the sum is over all those elements in \\(Y\\) that have been assigned a match) and then iterate this process of matching then minimising until some stopping criteria are met. We have the 2 following stopping criteria:</p> <ol> <li> <p>If 2 consecutive matchings are identical \\(\\beta_{t+1} = \\beta_t\\) then ICP gets stuck in an infinite loop, so we stop the iterations.</p> </li> <li> <p>The maximum number of iterations are reached. This is set by <code>icp_max_iter</code> which has default value 50.</p> </li> </ol> <p>The algorithm can be summarised as follows: <pre><code># Args:\n# X = m x 4 matrix (base positions padded)\n# Y = n x 3 matrix (target positions)\n# transform_initial = 4 x 3 initial transform\n# epsilon = distance threshold\n\n# Initialize\ntransform = transform_initial\nX = X @ transform\nneighb_prev = None\n\n# begin loop\nfor _ in range(n_iter):\n    # Find closest point in X to each point in Y\n    neighb = [argmin_k || X[k] - Y[j] || for j in range(n)]\n\n    # Remove these matches if they are above the neighb_dist_thresh\n    neighb = [neighb [j] if || X[neighb[j]] - Y[j] || &lt; epsilon,\n              else None for j in range(n)]\n\n    # Terminate if no change in neighbours\n    if neighb == neighb_prev:\n        QUIT\n\n    # Update transform\n    transform_update = argmin_B sum_j || X[neighb[j]] @ B - Y[j] || ** 2\n    X = X @ transform_update\n    transform = transform_update @ transform\n\n    # Update neighb_prev\n    neighb_prev = neighb\n</code></pre></p>"},{"location":"register/#2-implementation","title":"2. Implementation","text":"<p>Let \\(X_{r, c}\\) be the \\(n_{\\textrm{spots}}(r,c) \\times 3\\) matrix of all the spots found on round \\(r\\) channel \\(c\\).</p> Min Spots Criterion <p>ICP will not run on a tile, round, channel with too few spots. This threshold is set by <code>icp_min_spots</code> which has default value 100.</p>"},{"location":"register/#round-transform","title":"Round Transform","text":"<p>To compute the round transforms \\(B_r\\), we first adjust \\(X_{r_{\\textrm{ref}}, c_{\\textrm{ref}}}\\) by the flow to yield \\(\\mathcal{F}_r(X_{r_{\\textrm{ref}}, c_{\\textrm{ref}}})\\), which should approximately put the anchor spots in round \\(r\\) coordinates. We align these to the target points \\(X_{r, c_{\\textrm{ref}}}\\). As a formula this reads as</p> \\[ B_r = \\textrm{ICP} (\\textrm{base} = \\mathcal{F}_r(X_{r_{\\textrm{ref}}, c_{\\textrm{ref}}}), \\quad \\textrm{target} = X_{r, c_{\\textrm{ref}}}). \\] <p>This should capture any systematic affine errors in the flow field \\(\\mathcal{F}_r\\).</p>"},{"location":"register/#channel-transform","title":"Channel Transform","text":"<p>To compute the channel transforms \\(A_c\\) we align the anchor points \\(X_{r_{\\textrm{ref}}, c_{\\textrm{ref}}}\\) with all points in channel \\(c\\), regardless of round. We adjust these points to be in the anchor coordinate system. In a formula, this reads as</p> \\[ A_c = \\textrm{ICP} (\\textrm{base} = X_{r_{\\textrm{ref}}, c_{\\textrm{ref}}}, \\quad  \\textrm{target} = \\bigcup _r B_r ^{-1} (\\mathcal{F}_r ^{-1} (X_{r, c}))). \\] <p>The inverse transforms are used above because we are going from round \\(r\\) coordinates to round \\(r_{\\textrm{ref}}\\) coordinates, which is opposite to the way we computed the transforms.</p> <p>The chain of transforms is captured in the figure below:</p> <p>  Chain of transformations learnt for each round and channel. </p>"},{"location":"register/#diagnostics","title":"Diagnostics","text":"<p>Problems in registration can ruin several downstream analyses. These problems can be  diagnosed by looking at the Registration Viewer, as follows:</p> <pre><code>from coppafisher import Notebook, RegistrationViewer\n\nnb_file = \"/path/to/notebook\"\nconfig_file = \"/path/to/config.ini\"\nnb = Notebook(nb_file)\nrv = RegistrationViewer(nb, config_file)\n</code></pre> <p>This will open a viewer with the following home screen:</p> <p>  The Registration Viewer  </p> <p>This shows the round registration on the top row and the channel registration on the bottom row. This is displayed as follows:</p> <ul> <li> <p>Each image in the top row shows a small patch of \\((r_{\\textrm{ref}}, c_{\\textrm{dapi}})\\) in red, overlaid with \\((r, c_{\\textrm{dapi}})\\) in green.</p> </li> <li> <p>Each image in the bottom row shows a small patch of \\((r_{\\textrm{ref}}, c_{\\textrm{ref}})\\) in red, overlaid with \\((r_{\\textrm{mid}}, c)\\) in green.</p> </li> </ul> <p>Errors in registration may occur because of poor optical flow or ICP. The home screen shows small snippets of the images which indicate the overall quality of the registration. If these all look good, then the registration is likely fine. If not, then the options in the left panel will help diagnose the reason for poor round or channel registration.</p>"},{"location":"register/#different-methods","title":"Different Methods","text":"<p>There are 2 sliders at the bottom of the viewer. The z-slider allows you to move through the z-planes, while the method slider allows you to choose between different methods of displaying the images. The methods are as follows:</p> <ol> <li> <p>No Registration: This shows the images without any registration. This is useful to see how big the misalignments are.</p> </li> <li> <p>Optical Flow: This shows the images after the optical flow has been applied, but not the ICP transforms \\(A_{trc}\\). The channel transforms shown here use the optical flow plus the initial affine transform \\(\\tilde{A}_c\\) learnt from the fluorescent bead images.</p> </li> <li> <p>Optical Flow + ICP: This shows the images after the optical flow has been applied, and the ICP transforms \\(A_{trc}\\) have been applied. This is the final registration.</p> </li> </ol> <p>Registration with Different Methods</p> <p>The figures below show a good example of the different stages of round registration. The largest changes are made by optical flow, while ICP makes smaller corrections.</p> No RegistrationOptical FlowOptical Flow + ICP <p><p> </p></p> <p><p> </p></p> <p><p> </p></p> <p>The figures below show the different stages of channel registration. Here, image 1 is unregistered, image 2 is registered with optical flow and the initial affine transform, and image 3 is registered with optical flow and ICP. Most of the work done here is by ICP as the initial affine transform is not very good.</p> No RegistrationOptical Flow + Initial Affine TransformOptical Flow + ICP <p><p> </p></p> <p><p> </p></p> <p><p> </p></p>"},{"location":"register/#optical-flow-diagnostics","title":"Optical Flow Diagnostics","text":"<p>The Optical Flow Viewer can be selected on the left hand panel to view the optical flow fields for a particular round. This will open a screen like the one below:</p> <p>  The Optical Flow Viewer. </p> <p>This shows 3 columns of images:</p> <ol> <li> <p>No Flow: This shows \\((r_{\\textrm{ref}}, c_{\\textrm{dapi}})\\) in red, overlaid with \\((r, c_{\\textrm{dapi}})\\) in green before optical flow has been applied.</p> </li> <li> <p>Raw Flow: This shows \\((r_{\\textrm{ref}}, c_{\\textrm{dapi}})\\) in red, overlaid with \\((r, c_{\\textrm{dapi}})\\) in green after the raw flow has been applied.</p> </li> <li> <p>Smoothed Flow: This shows \\((r_{\\textrm{ref}}, c_{\\textrm{dapi}})\\) in red, overlaid with \\((r, c_{\\textrm{dapi}})\\) in green after the smoothed flow has been applied.</p> </li> </ol> <p>Rows 2, 3 and 4 show the raw and smooth flows in the \\(y\\), \\(x\\) and \\(z\\) directions respectively, while row 5 shows the correlation between the raw flow and the target image (this is the score \\(\\lambda(\\mathbf{x})\\) which is used to compute the smoothed flow).</p> <p>Optical Flow Viewer Example</p> <p>The figures below show an example of the different stages of optical flow. No flow shows a lot of misalignment. The raw flow shows the initial flow field, which is right in most places but wrong in others (particularly at edges). The smoothed flow is the final flow field, which is much better than the raw flow.</p> No FlowRaw FlowSmoothed Flow <p><p> </p></p> <p><p> </p></p> <p><p> </p></p> <p>The figure below is a closer look at the raw and smoothed flow fields, with the correlation plotted below them in blue.</p> <p><p> </p></p>"},{"location":"register/#icp-diagnostics","title":"ICP Diagnostics","text":"<p>Several diagnostics are available for ICP, and can be selected from the left hand panel. These viewers either show summary statistics or point clouds used to compute the transforms.</p>"},{"location":"register/#summary-statistics","title":"Summary Statistics","text":"<p>These show things like the average shift and scale for each round and channel and the convergence rates of each round and channel. This is useful for identifying outliers for some round or channel.</p> <p>Summary Statistics</p> <p>The figure below shows the shifts and scales of the ICP correction for each round and channel of a particular tile. These numbers alone do not tell us the whole picture about the affine transforms (for example they don't tell us about the rotation), but they can be useful for identifying outliers, and seeing how much work ICP is doing.</p> <p>In this image, very bright or very dark columns indicate large round corrections, while very bright or very dark rows indicate large channel corrections. Take note of the following points:</p> <ul> <li>The round corrections are largest in z.</li> <li>The channel corrections are largest in x and y.</li> <li>The channel scales and shifts are very similar in channels separated by a multiple of 4. This is because these channels come from the same camera, and therefore have roughly the same offset.</li> <li>Even though these scales are very small (around 1.003 at most), the images have size around 2000 pixels. This means that if we didn't correct for these scales, the images would be off by around 6 pixels, which is a lot.</li> </ul> <p><p> </p></p>"},{"location":"register/#point-clouds","title":"Point Clouds","text":"<p>These show the point clouds used to compute the round corrections \\(B_r\\) and channel corrections \\(A_c\\). This is much more detailed than the summary statistics and can be used to understand why convergence fails in certain cases.</p> <p>Point Clouds</p> <p>The figure below shows the point clouds used to compute the channel correction \\(A_c\\) for \\(c = 5\\).</p> <ul> <li>The white circles are the points from \\((r_{\\textrm{ref}}, c_{\\textrm{ref}})\\),</li> <li>the red crosses are the points from \\((r_{\\textrm{mid}}, c)\\).</li> <li>The cyan lines show the matches between points in the unaligned point clouds,</li> <li>the blue lines show the matches between points in the aligned point clouds.</li> <li>The yellow background image is bright in places where there are many matches and dark where there are few.</li> </ul> No RegistrationChannel Correction <p><p> </p></p> <p><p> </p></p> <p>The figure below shows the point clouds used to compute the round correction \\(B_r\\) for \\(r = 1\\). This viewer has the same components as the channel correction viewer but it defaults to showing all z-planes, as this is what ICP corrects for the most.</p> No RegistrationRound Correction <p><p> </p></p> <p><p> </p></p>"},{"location":"register/#registered-image-diagnostic","title":"Registered Image Diagnostic","text":"<p>The RegistrationViewer is great for diagnosing issues with the overall registration of images. But, if you want a particular area of interest, you can view the final registered images for every round/channel in a specific region of a tile. To do this</p> <pre><code>from coppafisher import Notebook\nfrom coppafisher.plot import view_registered_images\n\nnb = Notebook(\"/path/to/notebook\")\nview_registered_images(nb, tile)\n</code></pre> <p>where tile is the tile's index. By default, a 400x400x5 subset is gathered with bottom-left corner at (0, 0, 0). But, you can specify the region of interest by</p> <pre><code>from coppafisher import Notebook\nfrom coppafisher.plot import view_registered_images\n\nnb = Notebook(\"/path/to/notebook\")\nview_registered_images(nb, tile, ((ymin, ymax), (xmin, xmax), (zmin, zmax)))\n</code></pre> <p>where all minima and maxima must be integer numbers. The maxima are exclusive. As an example, <code>((2, 16), (0, 10), (5, 16))</code> would gather a 14x10x11 subset. See the docstring for further detail.</p> <p>Use the layer list on the left of the napari window to toggle the visibility of images.</p>"},{"location":"stitch/","title":"Stitch","text":"<p>The stitch section is the part of the pipeline responsible for creating a global coordinate system. This is done by looking at the overlapping regions between tiles and seeing how they have deviated from their expected positions.</p> <p> A Stitched collection of 6 tiles.  </p>"},{"location":"stitch/#algorithm","title":"Algorithm","text":"<p>The origin of each tile \\(t_i\\), which we call \\(\\mathbf{X}_i\\) is the position of its top left corner in the global coordinate system. Each tile \\(t_i\\) is given a nominal origin \\(\\mathbf{\\tilde{X}}_i\\) given by</p> \\[ \\mathbf{\\tilde{X}}_i = T(1-r) \\bigg( Y_i, X_i, 0 \\bigg), \\] <p>where</p> <ul> <li> <p>\\(T\\) is the size in pixels of the tile. We typically have \\(T = 2304\\),</p> </li> <li> <p>\\(r \\in (0, 1)\\) is the expected overlap between tiles and is chosen on the microscope,</p> </li> <li> <p>\\(Y_i\\) and \\(X_i\\) are the integer indices of the tile position in y and x respectively,</p> </li> <li> <p>we are using our default system of writing vectors in \\(yxz\\) format.</p> </li> </ul> <p>These origins are corrected by shifts \\(\\mathbf{S}_i\\) which capture small deviations from the nominal origins, ie:  \\(\\mathbf{X}_i = \\mathbf{\\tilde{X}}_i + \\mathbf{S}_i\\). These shifts are found as follows:</p> <ol> <li>     Compute shift $\\mathbf{v_{ij}}$ between the overlapping region of all adjacent tiles $t_i$ and $t_j$ using phase correlation. This would be $\\mathbf{0}$ if there were no deviations from the expected origins.   </li> <li>     Assign each shift $\\mathbf{v}_{ij}$ a score $\\lambda_{ij}$. We use      $$     \\lambda_{ij} = \\mathrm{corr}_ {\\mathbf{x}}(t_i(\\mathbf{x - v_{ij}}), t_j(\\mathbf{x}))^2.     $$   </li> <li>     We typically have about twice as many independent shifts as tiles (one south and one east for each non-boundary tile). This means our problem is over-constrained and doesn't have an exact solution. We can get an approximate solution for each shift $\\mathbf{S_i}$ by minimizing the loss function      $$     L(\\mathbf{S}) = \\sum_{i, j \\ \\mathrm{neighb}} \\lambda_{ij} |\\mathbf{S}_i - \\mathbf{S}_j - \\mathbf{v_{ij}}|^2,     $$      which is just saying that the deviations from the nominal origins for tiles $i$ and $j$ should be close to the observed deviations $\\mathbf{v_{ij}}$, and moreover that we should care more about making these similar when the deviations $\\mathbf{v_{ij}}$ are high quality, i.e., $\\lambda_{ij}$ is large.   </li> <li>     Differentiating the quadratic equation above gives a linear equation $\\mathbf{AS} = \\mathbf{B}$. However, $\\mathbf{A}$ is not invertible, so this does not have a unique solution (any common translation of all $\\mathbf{S}_i$ is another solution). We therefore solve for $\\mathbf{S}$ by minimizing a second loss function      $$     J(\\mathbf{S}) = ||\\mathbf{AS} - \\mathbf{B}||^2,     $$     which just says that we take the smallest of all the shifted solutions for $\\mathbf{S}$. This could have also been achieved by adding a regularization term $\\beta ||\\mathbf{S}||^2$ to the original loss function $L$.   </li> </ol>"},{"location":"stitch/#image-fusing","title":"Image Fusing","text":"<p>Once we have the final origins \\(\\mathbf{X}_i\\), we can fuse the images together. Overlapping regions are linearly tapered to avoid sharp transitions.</p> <p> Tapered edges can be seen clearly when some tiles finish in $z$ before others.  </p>"},{"location":"stitch/#global-coordinates-and-duplicate-spots","title":"Global Coordinates and Duplicate Spots","text":"<p>Each pixel \\(p\\) has local coordinate \\(\\mathbf{q}_p\\) which we can convert to global coordinates \\(\\mathbf{Q}_p\\)  by adding the origin of pixel \\(p\\)'s parent tile, ie:  \\(\\mathbf{Q}_p = \\mathbf{q}_p + \\mathbf{X}_{t(p)}\\).</p> <p>As discussed above, this is useful for viewing the spots in a global coordinate frame. It also allows us to remove duplicate spots at the overlap between tiles. This reduces computation time and ensures that no genes are double counted, which would skew the results of downstream analysis.</p> <p>When performing gene assignments, we only use the pixels \\(p\\) on tile \\(t\\) whose closest tile centre in global coordinates is tile \\(t\\). This takes care of duplicate spots in a way which doesn't actually have to view 2 spots overlapping in global coordinates, which would be error-prone.</p> <p> We only keep the spots on tile $t$ who are closer to the centre of $t$ than any other tile.  </p>"},{"location":"stitch/#diagnostics","title":"Diagnostics","text":""},{"location":"stitch/#view-stitch-checkerboard","title":"View Stitch Checkerboard","text":"<pre><code>from coppafisher.plot.stitch import view_stitch_checkerboard\nview_stitch_checkerboard(nb)\n</code></pre> <p>This function plots tiles in an alternating green and red checkerboard pattern with overlapping regions in yellow.</p> <p> </p>"},{"location":"troubleshoot/","title":"Troubleshoot","text":""},{"location":"troubleshoot/#pipeline-crash","title":"Pipeline crash","text":"<p>If the coppafisher pipeline is crashing, first read the error message. If there is a suggestion about how to fix the issue in the config, try changing the config variable and run the pipeline again. If the suggestion does not make sense to you, feel free to reach out to the developer(s) for help or create an issue on GitHub!</p>"},{"location":"troubleshoot/#memory-crash-at-omp","title":"Memory crash at OMP","text":"<p>Try reducing <code>subset_pixels</code> in the OMP config. This will cause OMP to compute on fewer pixels at time. It has a minimal effect on compute times, but will lower the RAM/VRAM usage. By default, the subset pixel number is found on the fly based on the PC's hardware, you can see this by looking at the pipeline.log file and searching for <code>subset_pixels</code>.</p>"}]}